{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wanted-grade",
   "metadata": {
    "id": "wanted-grade"
   },
   "source": [
    "# Run inference\n",
    "Ref: http://trillium.tech/ml4floods/content/ml4ops/HOWTO_Run_Inference_on_new_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "encouraging-whole",
   "metadata": {
    "id": "encouraging-whole"
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "from models import flooding_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-brake",
   "metadata": {
    "id": "instrumental-brake"
   },
   "source": [
    "## Step 1: Get config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tutorial-coordinator",
   "metadata": {
    "id": "tutorial-coordinator",
    "outputId": "4495dddb-521b-46d2-e9ea-e90fa6975c0b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Config for experiment:  training_flooding\n",
      "{   'data_params': {   'batch_size': 32,\n",
      "                       'bucket_id': 'ml4cc_data_lake',\n",
      "                       'channel_configuration': 'all',\n",
      "                       'download': {'test': True, 'train': True, 'val': True},\n",
      "                       'filter_windows': {   'apply': False,\n",
      "                                             'threshold_clouds': 0.5,\n",
      "                                             'version': 'v1'},\n",
      "                       'input_folder': 'S2',\n",
      "                       'loader_type': 'local',\n",
      "                       'num_workers': 4,\n",
      "                       'path_to_splits': '/mnt/d/Flooding/worldfloods_v1_sample',\n",
      "                       'target_folder': 'gt',\n",
      "                       'test_transformation': {'normalize': True},\n",
      "                       'train_test_split_file': '2_PROD/2_Mart/worldfloods_v1_0/train_test_split.json',\n",
      "                       'train_transformation': {'normalize': True},\n",
      "                       'window_size': [256, 256]},\n",
      "    'deploy': False,\n",
      "    'experiment_name': 'training_flooding',\n",
      "    'gpus': '0',\n",
      "    'model_params': {   'hyperparameters': {   'channel_configuration': 'all',\n",
      "                                               'early_stopping_patience': 4,\n",
      "                                               'label_names': [   'land',\n",
      "                                                                  'water',\n",
      "                                                                  'cloud'],\n",
      "                                               'lr': 0.0001,\n",
      "                                               'lr_decay': 0.5,\n",
      "                                               'lr_patience': 2,\n",
      "                                               'max_epochs': 10,\n",
      "                                               'max_tile_size': 256,\n",
      "                                               'metric_monitor': 'val_dice_loss',\n",
      "                                               'model_type': 'unet',\n",
      "                                               'num_channels': 13,\n",
      "                                               'num_classes': 3,\n",
      "                                               'val_every': 1,\n",
      "                                               'weight_per_class': [   1.93445299,\n",
      "                                                                       36.60054169,\n",
      "                                                                       2.19400729]},\n",
      "                        'max_tile_size': 256,\n",
      "                        'model_folder': 'train_models',\n",
      "                        'model_version': 'v1',\n",
      "                        'test': False,\n",
      "                        'train': True},\n",
      "    'resume_from_checkpoint': False,\n",
      "    'seed': 12,\n",
      "    'test': False,\n",
      "    'train': False}\n"
     ]
    }
   ],
   "source": [
    "from ml4floods.models.config_setup import get_default_config\n",
    "\n",
    "experiment_name = \"WFV1_unet\"\n",
    "prod_dev = \"2_PROD\"\n",
    "\n",
    "config_fp = \"train_models/training_flooding/config.json\"\n",
    "config = get_default_config(config_fp)\n",
    "config.data_params.data_params='ml4cc_data_lake'\n",
    "\n",
    "# The max_tile_size param controls the max size of patches that are fed to the NN. If you're in a memory contrained environment set this value to 128\n",
    "# config[\"model_params\"][\"max_tile_size\"] = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-variable",
   "metadata": {
    "id": "municipal-variable"
   },
   "source": [
    "## Step 2: Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bd9b544-a5e1-4b17-8a68-fc0eaf72bbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WorldFloodsModel(\n",
       "  (network): UNet(\n",
       "    (dconv_down1): Sequential(\n",
       "      (0): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (dconv_down2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (dconv_down3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (dconv_down4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (dconv_up3): Sequential(\n",
       "      (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (dconv_up2): Sequential(\n",
       "      (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (dconv_up1): Sequential(\n",
       "      (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv_last): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.flooding_model import WorldFloodsModel\n",
    "importlib.reload(flooding_model)\n",
    "\n",
    "model = WorldFloodsModel(config.model_params)\n",
    "model\n",
    "\n",
    "model.eval()\n",
    "model.to(\"cuda\") # comment this line if your machine does not have GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aggregate-retirement",
   "metadata": {
    "id": "aggregate-retirement",
    "outputId": "42a245d0-9ac3-443d-f297-d29e3e1b67c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting model inference function\n",
      "Max tile size: 256\n"
     ]
    }
   ],
   "source": [
    "from models.inference import get_model_inference_function\n",
    "\n",
    "inference_function = get_model_inference_function(model, config, apply_normalization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-howard",
   "metadata": {
    "id": "biological-howard"
   },
   "source": [
    "## Step 3: Helper functions for plotting and reading some demo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "robust-consequence",
   "metadata": {
    "id": "robust-consequence",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "from rasterio import plot as rasterioplt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from typing import Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from ml4floods.data.worldfloods.configs import BANDS_S2, CHANNELS_CONFIGURATIONS\n",
    "from ml4floods.visualization.plot_utils import download_tiff\n",
    "import os\n",
    "    \n",
    "\n",
    "@torch.no_grad()\n",
    "def read_inference_pair(tiff_inputs:str, folder_ground_truth:str, \n",
    "                        window:Optional[Union[rasterio.windows.Window, Tuple[slice,slice]]], \n",
    "                        return_ground_truth: bool=False, channels:bool=None, \n",
    "                        folder_permanent_water:Optional[str]=None,\n",
    "                        cache_folder:Optional[str]=None) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, rasterio.Affine]:\n",
    "    \"\"\"\n",
    "    Read a pair of layers from the worldfloods bucket and return them as Tensors to pass to a model, return the transform for plotting with lat/long\n",
    "    \n",
    "    Args:\n",
    "        tiff_inputs: filename for layer in worldfloods bucket\n",
    "        folder_ground_truth: folder name to be replaced by S2 in the input\n",
    "        window: window of layer to use\n",
    "        return_ground_truth: flag to indicate if paired gt layer should be returned\n",
    "        channels: list of channels to read from the image\n",
    "        folder_permanent_water: Folder with permanent water layer raster.\n",
    "        cache_folder: if provided and tiff_inputs are in a google bucket it will download the tiffs before opening them.\n",
    "    \n",
    "    Returns:\n",
    "        (torch_inputs, torch_targets, transform): inputs Tensor, gt Tensor, transform for plotting with lat/long\n",
    "    \"\"\"\n",
    "    \n",
    "    if cache_folder is not None and tiff_inputs.startswith(\"gs\"):\n",
    "        tiff_inputs = download_tiff(cache_folder, tiff_inputs, folder_ground_truth, folder_permanent_water)\n",
    "    \n",
    "    tiff_targets = tiff_inputs.replace(\"/S2/\", folder_ground_truth)\n",
    "\n",
    "    with rasterio.open(tiff_inputs, \"r\") as rst:\n",
    "        inputs = rst.read((np.array(channels) + 1).tolist(), window=window)\n",
    "        # Shifted transform based on the given window (used for plotting)\n",
    "        transform = rst.transform if window is None else rasterio.windows.transform(window, rst.transform)\n",
    "        torch_inputs = torch.Tensor(inputs.astype(np.float32)).unsqueeze(0)\n",
    "    \n",
    "    if folder_permanent_water is not None:\n",
    "        tiff_permanent_water = tiff_inputs.replace(\"/S2/\", folder_permanent_water)\n",
    "        with rasterio.open(tiff_permanent_water, \"r\") as rst:\n",
    "            permanent_water = rst.read(1, window=window)  \n",
    "            torch_permanent_water = torch.tensor(permanent_water)\n",
    "    else:\n",
    "        torch_permanent_water = torch.zeros_like(torch_inputs)\n",
    "        \n",
    "    if return_ground_truth:\n",
    "        with rasterio.open(tiff_targets, \"r\") as rst:\n",
    "            targets = rst.read(1, window=window)\n",
    "        \n",
    "        torch_targets = torch.tensor(targets).unsqueeze(0)\n",
    "    else:\n",
    "        torch_targets = torch.zeros_like(torch_inputs)\n",
    "    \n",
    "    return torch_inputs, torch_targets, torch_permanent_water, transform\n",
    "\n",
    "COLORS_WORLDFLOODS = np.array([[0, 0, 0], # invalid\n",
    "                               [139, 64, 0], # land\n",
    "                               [0, 0, 139], # water\n",
    "                               [220, 220, 220]], # cloud\n",
    "                              dtype=np.float32) / 255\n",
    "\n",
    "INTERPRETATION_WORLDFLOODS = [\"invalid\", \"land\", \"water\", \"cloud\"]\n",
    "\n",
    "COLORS_WORLDFLOODS_PERMANENT = np.array([[0, 0, 0], # 0: invalid\n",
    "                                         [139, 64, 0], # 1: land\n",
    "                                         [237, 0, 0], # 2: flood_water\n",
    "                                         [220, 220, 220], # 3: cloud\n",
    "                                         [0, 0, 139], # 4: permanent_water\n",
    "                                         [60, 85, 92]], # 5: seasonal_water\n",
    "                                        dtype=np.float32) / 255\n",
    "\n",
    "INTERPRETATION_WORLDFLOODS_PERMANENT = [\"invalid\", \"land\", \"flood water\", \"cloud\", \"permanent water\", \"seasonal water\"]\n",
    "\n",
    "def gt_with_permanent_water(gt: np.ndarray, permanent_water: np.ndarray)->np.ndarray:\n",
    "    \"\"\" Permanent water taken from: https://developers.google.com/earth-engine/datasets/catalog/JRC_GSW1_2_YearlyHistory\"\"\"\n",
    "    gt[(gt == 2) & (permanent_water == 3)] = 4 # set as permanent_water\n",
    "    gt[(gt == 2) & (permanent_water == 2)] = 5 # set as seasonal water\n",
    "        \n",
    "    return gt\n",
    "            \n",
    "\n",
    "def get_cmap_norm_colors(color_array, interpretation_array):\n",
    "    cmap_categorical = colors.ListedColormap(color_array)\n",
    "    norm_categorical = colors.Normalize(vmin=-.5,\n",
    "                                        vmax=color_array.shape[0]-.5)\n",
    "    patches = []\n",
    "    for c, interp in zip(color_array, interpretation_array):\n",
    "        patches.append(mpatches.Patch(color=c, label=interp))\n",
    "    \n",
    "    return cmap_categorical, norm_categorical, patches\n",
    "\n",
    "\n",
    "def plot_inference_set(inputs: torch.Tensor, targets: torch.Tensor, \n",
    "                       predictions: torch.Tensor, permanent_water: torch.Tensor, transform: rasterio.Affine, \n",
    "                       channel_configuration:str)->None:\n",
    "    \"\"\"\n",
    "    Plots inputs, targets and prediction into lat/long visualisation\n",
    "    \n",
    "    Args:\n",
    "        inputs: input Tensor\n",
    "        targets: gt target Tensor\n",
    "        prediction: predictions output by model (softmax, argmax already applied)\n",
    "        permanent_water: permanent water raster\n",
    "        transform: transform used to plot with lat/long\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(2,2,figsize=(16,16))\n",
    "    \n",
    "    inputs_show = inputs.cpu().numpy().squeeze()\n",
    "    targets_show = targets.cpu().numpy().squeeze()\n",
    "    permanent_water_show = permanent_water.numpy().squeeze()\n",
    "    \n",
    "    targets_show = gt_with_permanent_water(targets_show, permanent_water_show)\n",
    "    \n",
    "    \n",
    "    # Color categories {-1: invalid, 0: land, 1: water, 2: clouds}\n",
    "    \n",
    "    cmap_preds, norm_preds, patches_preds = get_cmap_norm_colors(COLORS_WORLDFLOODS, INTERPRETATION_WORLDFLOODS)\n",
    "    cmap_gt, norm_gt, patches_gt = get_cmap_norm_colors(COLORS_WORLDFLOODS_PERMANENT, INTERPRETATION_WORLDFLOODS_PERMANENT)\n",
    "    \n",
    "    # +1 because value 0 is invalid\n",
    "    prediction_show = (predictions + 1).cpu().numpy().astype(float)\n",
    "    \n",
    "    band_names_current_image = [BANDS_S2[iband] for iband in CHANNELS_CONFIGURATIONS[channel_configuration]]\n",
    "    \n",
    "    if all(b in band_names_current_image for b in [\"B4\", \"B3\", \"B2\"]):\n",
    "        bands = [band_names_current_image.index(b) for b in [\"B4\", \"B3\", \"B2\"]]\n",
    "        rgb = np.clip(inputs_show[bands, :, :]/3000.,0,1)\n",
    "        rasterioplt.show(rgb,transform=transform,ax=ax[0,0])\n",
    "        ax[0,0].set_title(\"RGB Composite\")\n",
    "    else:\n",
    "        print(\"Can't show RGB Composite image lacks bands\")\n",
    "    \n",
    "    if all(b in band_names_current_image for b in [\"B11\", \"B8\", \"B4\"]):\n",
    "        bands_false_composite = [BANDS_S2.index(b) for b in [\"B11\", \"B8\", \"B4\"]] # swir_1, nir, red composite\n",
    "        false_rgb = np.clip(inputs_show[bands_false_composite, :, :]/3000.,0,1)\n",
    "        rasterioplt.show(false_rgb,transform=transform,ax=ax[0,1])\n",
    "        ax[0,1].set_title(\"SWIR1,NIR,R Composite\")\n",
    "    else:\n",
    "        print(\"Can't show SWIR1,NIR,R Composite image lacks bands\")\n",
    "        \n",
    "    rasterioplt.show(targets_show,transform=transform,ax=ax[1,0], cmap=cmap_gt, norm=norm_gt,\n",
    "                     interpolation='nearest')\n",
    "    rasterioplt.show(prediction_show, transform=transform, ax=ax[1,1],cmap=cmap_preds, norm=norm_preds,\n",
    "                     interpolation='nearest')\n",
    "    \n",
    "    ax[1,0].set_title(\"Ground Truth\")\n",
    "    ax[1,0].legend(handles=patches_gt,\n",
    "                 loc='upper right')\n",
    "    \n",
    "    ax[1,1].set_title(\"Model prediction\")\n",
    "    ax[1,1].legend(handles=patches_preds,\n",
    "                   loc='upper right')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-porter",
   "metadata": {
    "id": "smart-porter"
   },
   "source": [
    "## Perform Inference using the `inference_function`\n",
    "\n",
    "The `inference_function` let us run the model on large tiles. For doing this it follows the tiling and stiching strategy\n",
    "described in https://arxiv.org/abs/1805.12219."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "southeast-hindu",
   "metadata": {
    "id": "southeast-hindu",
    "outputId": "5b0e016f-13c0-4ec7-b63b-bc124fc406a1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-76704af426f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Compute the prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_inputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch_size, num_classes, h, w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch_size, h, w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m plot_inference_set(torch_inputs, torch_targets, prediction, torch_permanent_water, transform, \n",
      "\u001b[0;32m~/viplab_projects/satellite-knowledge-distillation/models/inference.py\u001b[0m in \u001b[0;36mpred_fun_final\u001b[0;34m(ti)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mti_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mti\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_tile_size\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 return predbytiles(pred_fun,\n\u001b[0m\u001b[1;32m    106\u001b[0m                                    \u001b[0minput_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mti_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                                    tile_size=max_tile_size)\n",
      "\u001b[0;32m~/viplab_projects/satellite-knowledge-distillation/models/inference.py\u001b[0m in \u001b[0;36mpredbytiles\u001b[0;34m(pred_function, input_batch, tile_size, pad_size, device)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mvals_to_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslice_pad\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mcnn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals_to_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mcnn_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Expected 4-band prediction (after softmax)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/viplab_projects/satellite-knowledge-distillation/models/inference.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mshape_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0mshape_new_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmodule_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmodule_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from models.inference import get_channel_configuration_bands\n",
    "import os\n",
    "\n",
    "\n",
    "cache_folder = \"/mnt/d/Flooding/worldfloods_v1_sample/tiffs_for_inference\"\n",
    "os.makedirs(cache_folder, exist_ok=True)\n",
    "\n",
    "channel_configuration = config.model_params.hyperparameters.channel_configuration\n",
    "# tiff_s2, window, channels = \"gs://ml4cc_data_lake/0_DEV/2_Mart/worldfloods_v1_0/val/S2/RS2_20161008_Water_Extent_Corail_Pestel.tif\", None, get_channel_configuration_bands(channel_configuration)\n",
    "tiff_s2, window, channels = \"gs://ml4cc_data_lake/2_PROD/2_Mart/worldfloods_v1_0/val/S2/RS2_20161008_Water_Extent_Corail_Pestel.tif\", None, get_channel_configuration_bands(channel_configuration)\n",
    "\n",
    "# Load the image and ground truth\n",
    "torch_inputs, torch_targets, \\\n",
    "   torch_permanent_water, transform = read_inference_pair(tiff_s2,folder_ground_truth=\"/gt/\", \n",
    "                                                          window=window, return_ground_truth=True, channels=channels,\n",
    "                                                          folder_permanent_water=\"/PERMANENTWATERJRC/\",\n",
    "                                                          cache_folder=cache_folder)\n",
    "\n",
    "# Compute the prediction\n",
    "outputs = inference_function(torch_inputs) # (batch_size, num_classes, h, w)\n",
    "prediction = torch.argmax(outputs, dim=1).long() # (batch_size, h, w)\n",
    "plot_inference_set(torch_inputs, torch_targets, prediction, torch_permanent_water, transform, \n",
    "                   channel_configuration=channel_configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-shipping",
   "metadata": {
    "id": "acting-shipping"
   },
   "source": [
    "### Bonus: vectorise the water masks and plot them\n",
    "\n",
    "In the code bellow `data_out` is a `GeoDataFrame` object. You can save it as a shapefile with [`save_file`](https://geopandas.org/docs/user_guide/io.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-transportation",
   "metadata": {
    "id": "disabled-transportation",
    "outputId": "c10bde8e-e00e-4d62-e8de-a3d6e0952e3c"
   },
   "outputs": [],
   "source": [
    "from ml4floods.models import postprocess\n",
    "from ml4floods.visualization import plot_utils\n",
    "import geopandas as gpd\n",
    "\n",
    "prob_water_mask = outputs[0,1].cpu().numpy()\n",
    "binary_water_mask = prob_water_mask>.5\n",
    "\n",
    "geoms_polygons = postprocess.get_water_polygons(binary_water_mask, transform=transform)\n",
    "\n",
    "data_out = gpd.GeoDataFrame({\"geometry\": geoms_polygons, \"id\": np.arange(len(geoms_polygons))})\n",
    "fig, ax = plt.subplots(1,1, figsize=(12, 12))\n",
    "data_out.plot(\"id\",legend=True,categorical=True,ax=ax,facecolor=\"None\",edgecolor=\"1\",linewidth=3)\n",
    "plot_utils.plot_s2_rbg_image(torch_inputs[0].cpu().numpy(), transform=transform, ax=ax, alpha=.6,\n",
    "                             channel_configuration=channel_configuration)\n",
    "data_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-battery",
   "metadata": {
    "id": "roman-battery"
   },
   "source": [
    "## Lets try another image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-winner",
   "metadata": {
    "id": "correct-winner",
    "outputId": "cc43763c-8dc0-46b8-9558-81666cedafea",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tiff_s2, window, channels = \"gs://ml4cc_data_lake/2_PROD/2_Mart/worldfloods_v1_0/test/S2/EMSR347_07ZOMBA_DEL_v2_observed_event_a.tif\", None, get_channel_configuration_bands(config.model_params.hyperparameters.channel_configuration)\n",
    "\n",
    "torch_inputs, torch_targets, torch_permanent_water, transform = read_inference_pair(tiff_s2, folder_ground_truth=\"/gt/\", \n",
    "                                                                                    window=window, \n",
    "                                                                                    return_ground_truth=True, channels=channels,\n",
    "                                                                                    folder_permanent_water=\"/PERMANENTWATERJRC/\",\n",
    "                                                                                    cache_folder=cache_folder)\n",
    "\n",
    "outputs = inference_function(torch_inputs) # (batch_size, num_classes, h, w)\n",
    "prediction = torch.argmax(outputs, dim=1).long() # (batch_size, h, w)\n",
    "plot_inference_set(torch_inputs, torch_targets, prediction, torch_permanent_water, transform,channel_configuration=channel_configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-grass",
   "metadata": {
    "id": "neither-grass"
   },
   "source": [
    "### Bonus: vectorise the water masks and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-passion",
   "metadata": {
    "id": "collect-passion",
    "outputId": "76c7c969-8f6b-44a9-ad6b-eba06b1435c7"
   },
   "outputs": [],
   "source": [
    "prob_water_mask = outputs[0,1].cpu().numpy()\n",
    "binary_water_mask = prob_water_mask>.5\n",
    "\n",
    "geoms_polygons = postprocess.get_water_polygons(binary_water_mask, transform=transform)\n",
    "\n",
    "data_out = gpd.GeoDataFrame({\"geometry\": geoms_polygons, \"id\": np.arange(len(geoms_polygons))})\n",
    "fig, ax = plt.subplots(1,1, figsize=(12, 12))\n",
    "data_out.plot(\"id\",legend=True,categorical=True,ax=ax,facecolor=\"None\",edgecolor=\"1\",linewidth=3)\n",
    "plot_utils.plot_s2_rbg_image(torch_inputs[0].cpu().numpy(), transform=transform, ax=ax, alpha=.6,\n",
    "                             channel_configuration=channel_configuration)\n",
    "data_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-fountain",
   "metadata": {
    "id": "fixed-fountain"
   },
   "source": [
    "## Lets try another image from the new data prepared by the Janitors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-attachment",
   "metadata": {
    "id": "roman-attachment",
    "outputId": "04680856-e30c-4f2e-d014-f5bfd386faa1"
   },
   "outputs": [],
   "source": [
    "import rasterio.windows \n",
    "window = rasterio.windows.Window(col_off=1543, row_off=247, \n",
    "                                 width=2000, height=2000)\n",
    "tiff_s2, channels = \"gs://ml4cc_data_lake/2_PROD/1_Staging/WorldFloods/S2/EMSR501/AOI01/EMSR501_AOI01_DEL_MONIT01_r1_v1.tif\", get_channel_configuration_bands(config.model_params.hyperparameters.channel_configuration)\n",
    "\n",
    "torch_inputs, torch_targets, torch_permanent_water, transform = read_inference_pair(tiff_s2, folder_ground_truth=\"/GT/V_1_1/\", \n",
    "                                                                                    window=window, \n",
    "                                                                                    return_ground_truth=True, channels=channels,\n",
    "                                                                                    folder_permanent_water=\"/JRC/\",\n",
    "                                                                                    cache_folder=cache_folder)\n",
    "\n",
    "outputs = inference_function(torch_inputs) # (batch_size, num_classes, h, w)\n",
    "prediction = torch.argmax(outputs, dim=1).long() # (batch_size, h, w)\n",
    "plot_inference_set(torch_inputs, torch_targets, prediction, torch_permanent_water, transform,\n",
    "                   channel_configuration=channel_configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-commons",
   "metadata": {
    "id": "incredible-commons"
   },
   "source": [
    "### Bonus: vectorise the water masks and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-numbers",
   "metadata": {
    "id": "sporting-numbers",
    "outputId": "9ae40878-da35-4777-e56d-69656c7a5589"
   },
   "outputs": [],
   "source": [
    "prob_water_mask = outputs[0,1].cpu().numpy()\n",
    "binary_water_mask = prob_water_mask>.5\n",
    "\n",
    "geoms_polygons = postprocess.get_water_polygons(binary_water_mask, transform=transform)\n",
    "\n",
    "data_out = gpd.GeoDataFrame({\"geometry\": geoms_polygons, \"id\": np.arange(len(geoms_polygons))})\n",
    "fig, ax = plt.subplots(1,1, figsize=(12, 12))\n",
    "data_out.plot(\"id\",legend=False,categorical=True,ax=ax,facecolor=\"None\",edgecolor=\"1\",linewidth=3)\n",
    "plot_utils.plot_s2_rbg_image(torch_inputs[0].cpu().numpy(), transform=transform, ax=ax, alpha=.6,\n",
    "                            channel_configuration=channel_configuration)\n",
    "data_out.shape"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "colab": {
   "name": "HOWTO_Run_Inference_on_new_data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pt-gpu",
   "language": "python",
   "name": "pt-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
