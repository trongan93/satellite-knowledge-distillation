{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2,3,4,5,6,7\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-history",
   "metadata": {},
   "source": [
    "## Load flooding configuration file from local device or gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "toxic-watch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Config for experiment:  worldfloods_demo_test\n",
      "{   'data_params': {   'batch_size': 32,\n",
      "                       'bucket_id': 'ml4cc_data_lake',\n",
      "                       'channel_configuration': 'all',\n",
      "                       'download': {'test': True, 'train': True, 'val': True},\n",
      "                       'filter_windows': {   'apply': False,\n",
      "                                             'threshold_clouds': 0.5,\n",
      "                                             'version': 'v1'},\n",
      "                       'input_folder': 'S2',\n",
      "                       'loader_type': 'local',\n",
      "                       'num_workers': 4,\n",
      "                       'path_to_splits': 'worldfloods',\n",
      "                       'target_folder': 'gt',\n",
      "                       'test_transformation': {'normalize': True},\n",
      "                       'train_test_split_file': '2_PROD/2_Mart/worldfloods_v1_0/train_test_split.json',\n",
      "                       'train_transformation': {'normalize': True},\n",
      "                       'window_size': [256, 256]},\n",
      "    'deploy': False,\n",
      "    'experiment_name': 'worldfloods_demo_test',\n",
      "    'gpus': '0',\n",
      "    'model_params': {   'hyperparameters': {   'channel_configuration': 'all',\n",
      "                                               'early_stopping_patience': 4,\n",
      "                                               'label_names': [   'land',\n",
      "                                                                  'water',\n",
      "                                                                  'cloud'],\n",
      "                                               'lr': 0.0001,\n",
      "                                               'lr_decay': 0.5,\n",
      "                                               'lr_patience': 2,\n",
      "                                               'max_epochs': 10,\n",
      "                                               'max_tile_size': 256,\n",
      "                                               'metric_monitor': 'val_dice_loss',\n",
      "                                               'model_type': 'linear',\n",
      "                                               'num_channels': 13,\n",
      "                                               'num_classes': 3,\n",
      "                                               'val_every': 1,\n",
      "                                               'weight_per_class': [   1.93445299,\n",
      "                                                                       36.60054169,\n",
      "                                                                       2.19400729]},\n",
      "                        'model_folder': 'gs://ml4cc_data_lake/0_DEV/2_Mart/2_MLModelMart',\n",
      "                        'model_version': 'v1',\n",
      "                        'test': True,\n",
      "                        'train': True},\n",
      "    'resume_from_checkpoint': False,\n",
      "    'seed': 12,\n",
      "    'test': False,\n",
      "    'train': False}\n"
     ]
    }
   ],
   "source": [
    "from ml4floods.models.config_setup import get_default_config\n",
    "import pkg_resources\n",
    "\n",
    "# Set filepath to configuration files\n",
    "# config_fp = 'path/to/worldfloods_template.json'\n",
    "config_fp = pkg_resources.resource_filename(\"ml4floods\",\"models/configurations/worldfloods_template.json\")\n",
    "\n",
    "config = get_default_config(config_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-scope",
   "metadata": {},
   "source": [
    "## Step 2: Setup Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defined-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.experiment_name = 'training_flooding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "scientific-musician",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local dataset for this run\n",
      "Downloading /mnt/d/Flooding/worldfloods_v1_sample/train/S2 if needed\n",
      "Downloading /mnt/d/Flooding/worldfloods_v1_sample/train/gt if needed\n",
      "Downloading /mnt/d/Flooding/worldfloods_v1_sample/test/S2 if needed\n",
      "Downloading /mnt/d/Flooding/worldfloods_v1_sample/test/gt if needed\n",
      "Downloading /mnt/d/Flooding/worldfloods_v1_sample/val/S2 if needed\n",
      "Downloading /mnt/d/Flooding/worldfloods_v1_sample/val/gt if needed\n",
      "train 194151  tiles\n",
      "val 1284  tiles\n",
      "test 11  tiles\n",
      "CPU times: user 5.41 s, sys: 3.33 s, total: 8.74 s\n",
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from ml4floods.models.dataset_setup import get_dataset\n",
    "\n",
    "# config.data_params.batch_size = 96 # control this depending on the space on your GPU!\n",
    "config.data_params.loader_type = 'local'\n",
    "config.data_params.path_to_splits = \"/mnt/d/Flooding/worldfloods_v1_sample\" # local folder to download the data\n",
    "# config.data_params.train_test_split_file = \"2_PROD/2_Mart/worldfloods_v1_0/train_test_split_sample.json\"\n",
    "\n",
    "config.data_params[\"download\"] = {\"train\": True, \"val\": True, \"test\": True} # download only test data\n",
    "config.data_params.train_test_split_file = \"2_PROD/2_Mart/worldfloods_v1_0/train_test_split.json\" # use this to train with all the data\n",
    "config.data_params.num_workers = 7\n",
    "\n",
    "# If files are not in config.data_params.path_to_splits this will trigger the download of the products.\n",
    "dataset = get_dataset(config.data_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-harassment",
   "metadata": {},
   "source": [
    "## Verfify data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-driver",
   "metadata": {},
   "source": [
    "#### Verify training data\n",
    "Data format here: https://github.com/spaceml-org/ml4floods/blob/891fe602880586e7ac821d2f282bf5ec9d4c0795/ml4floods/data/worldfloods/dataset.py#L106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fallen-harbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6068\n"
     ]
    }
   ],
   "source": [
    "train_dl = dataset.train_dataloader()\n",
    "train_dl_iter = iter(train_dl)\n",
    "print(len(train_dl_iter))\n",
    "batch_train = next(train_dl_iter)\n",
    "\n",
    "# batch_train[\"image\"].shape, batch_train[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-spanking",
   "metadata": {},
   "source": [
    "Verify validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "injured-effect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "val_dl = dataset.val_dataloader()\n",
    "\n",
    "val_dl_iter = iter(val_dl)\n",
    "print(len(val_dl_iter))\n",
    "batch_val = next(val_dl_iter)\n",
    "\n",
    "# batch_val[\"image\"].shape, batch_val[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "significant-multiple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "test_dl = dataset.test_dataloader()\n",
    "\n",
    "test_dl_iter = iter(test_dl)\n",
    "print(len(test_dl_iter))\n",
    "\n",
    "batch_test = next(test_dl_iter)\n",
    "# batch_test[\"image\"].shape, batch_test[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-electron",
   "metadata": {},
   "source": [
    "### Plot batch by using ml4flood model \n",
    "check detail here: https://github.com/spaceml-org/ml4floods/blob/891fe602880586e7ac821d2f282bf5ec9d4c0795/ml4floods/data/worldfloods/dataset.py#L106"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bridal-needle",
   "metadata": {},
   "source": [
    "from models import flooding_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "flooding_model.plot_batch(batch_train[\"image\"])\n",
    "\n",
    "n_images=6\n",
    "fig, axs = plt.subplots(3,n_images, figsize=(18,10),tight_layout=True)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],axs=axs[0],max_clip_val=3500.)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],bands_show=[\"B11\",\"B8\", \"B4\"],\n",
    "                             axs=axs[1],max_clip_val=4500.)\n",
    "flooding_model.plot_batch_output_v1(batch_train[\"mask\"][:n_images, 0],axs=axs[2], show_axis=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-miller",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1, 256, 256)\n",
      "(32, 256, 256, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "from models import flooding_model\n",
    "flooding_model = importlib.reload(flooding_model)\n",
    "\n",
    "batch_train_rgb = flooding_model.batch_to_unnorm_rgb(batch_train[\"image\"])\n",
    "# batch_train_rgb.shape\n",
    "plt.imshow(batch_train_rgb[2])\n",
    "plt.show()\n",
    "\n",
    "batch_train_rgb_mask = flooding_model.batch_mask_to_rgb(batch_train[\"mask\"])\n",
    "plt.imshow(batch_train_rgb_mask[2])\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-cleanup",
   "metadata": {},
   "source": [
    "## Step 3: Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-surrey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_folder': 'gs://ml4cc_data_lake/0_DEV/2_Mart/2_MLModelMart',\n",
       " 'model_version': 'v1',\n",
       " 'hyperparameters': {'max_tile_size': 256,\n",
       "  'metric_monitor': 'val_dice_loss',\n",
       "  'channel_configuration': 'all',\n",
       "  'label_names': ['land', 'water', 'cloud'],\n",
       "  'weight_per_class': [1.93445299, 36.60054169, 2.19400729],\n",
       "  'model_type': 'linear',\n",
       "  'num_classes': 3,\n",
       "  'max_epochs': 10,\n",
       "  'val_every': 1,\n",
       "  'lr': 0.0001,\n",
       "  'lr_decay': 0.5,\n",
       "  'lr_patience': 2,\n",
       "  'early_stopping_patience': 4,\n",
       "  'num_channels': 13},\n",
       " 'train': True,\n",
       " 'test': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # folder to store the trained model (it will create a subfolder with the name of the experiment)\n",
    "config.model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "colonial-tiffany",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config\n",
      "{'max_tile_size': 256, 'metric_monitor': 'val_dice_loss', 'channel_configuration': 'all', 'label_names': ['land', 'water', 'cloud'], 'weight_per_class': [1.93445299, 36.60054169, 2.19400729], 'model_type': 'unet', 'num_classes': 3, 'max_epochs': 1, 'val_every': 1, 'lr': 0.0001, 'lr_decay': 0.5, 'lr_patience': 2, 'early_stopping_patience': 4, 'num_channels': 13}\n"
     ]
    }
   ],
   "source": [
    "config.model_params.model_folder = \"train_models\" \n",
    "os.makedirs(\"train_models\", exist_ok=True)\n",
    "config.model_params.test = False\n",
    "config.model_params.train = True\n",
    "config.model_params.hyperparameters.model_type = \"unet\" # Currently implemented: simplecnn, unet, linear\n",
    "print('config')\n",
    "print(config.model_params.hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "alternative-bonus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_folder': 'train_models',\n",
       " 'model_version': 'v1',\n",
       " 'hyperparameters': {'max_tile_size': 256,\n",
       "  'metric_monitor': 'val_dice_loss',\n",
       "  'channel_configuration': 'all',\n",
       "  'label_names': ['land', 'water', 'cloud'],\n",
       "  'weight_per_class': [1.93445299, 36.60054169, 2.19400729],\n",
       "  'model_type': 'unet_simple',\n",
       "  'num_classes': 3,\n",
       "  'max_epochs': 1,\n",
       "  'val_every': 1,\n",
       "  'lr': 0.0001,\n",
       "  'lr_decay': 0.5,\n",
       "  'lr_patience': 2,\n",
       "  'early_stopping_patience': 4,\n",
       "  'num_channels': 13},\n",
       " 'train': True,\n",
       " 'test': False}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "from models.flooding_model import WorldFloodsModel, DistilledTrainingModel\n",
    "importlib.reload(flooding_model)\n",
    "simple_model_params = copy.deepcopy(config.model_params)\n",
    "simple_model_params['hyperparameters']['model_type']=\"unet_simple\"\n",
    "\n",
    "model = DistilledTrainingModel(config.model_params, simple_model_params)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_weights_and_biases = False\n",
    "if setup_weights_and_biases:\n",
    "    import wandb\n",
    "    from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "    # UNCOMMENT ON FIRST RUN TO LOGIN TO Weights and Biases (only needs to be done once)\n",
    "    # wandb.login()\n",
    "    # run = wandb.init()\n",
    "\n",
    "    # Specifies who is logging the experiment to wandb\n",
    "    config['wandb_entity'] = 'ml4floods'\n",
    "    # Specifies which wandb project to log to, multiple runs can exist in the same project\n",
    "    config['wandb_project'] = 'worldfloods-notebook-demo-project'\n",
    "\n",
    "    wandb_logger = WandbLogger(\n",
    "        name=config.experiment_name,\n",
    "        project=config.wandb_project, \n",
    "        entity=config.wandb_entity\n",
    "    )\n",
    "else:\n",
    "    wandb_logger = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-teens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trained model will be stored in train_models/training_flooding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeaiserver/pt-gpu/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:360: UserWarning: Checkpoint directory train_models/training_flooding/checkpoint exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "experiment_path = f\"{config.model_params.model_folder}/{config.experiment_name}\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"{experiment_path}/checkpoint\",\n",
    "    save_top_k=True,\n",
    "    verbose=True,\n",
    "    monitor='val_dice_loss',\n",
    "    mode='min',\n",
    "#     prefix=''\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_dice_loss',\n",
    "    patience=10,\n",
    "    strict=False,\n",
    "    verbose=False,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint_callback, early_stop_callback]\n",
    "\n",
    "print(f\"The trained model will be stored in {config.model_params.model_folder}/{config.experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-charity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "config.gpus = 7 # which gpu to use\n",
    "\n",
    "# config.gpus = None # to not use GPU\n",
    "\n",
    "config.model_params.hyperparameters.max_epochs = 1 # train for maximum 4 epochs\n",
    "\n",
    "trainer = Trainer(\n",
    "    fast_dev_run=False,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=callbacks,\n",
    "    default_root_dir=f\"{config.model_params.model_folder}/{config.experiment_name}\",\n",
    "    accumulate_grad_batches=1,\n",
    "    gradient_clip_val=0.0,\n",
    "    auto_lr_find=False,\n",
    "    benchmark=False,\n",
    "    distributed_backend=None,\n",
    "    gpus=config.gpus,\n",
    "    max_epochs=config.model_params.hyperparameters.max_epochs,\n",
    "    check_val_every_n_epoch=config.model_params.hyperparameters.val_every,\n",
    "    log_gpu_memory=False,\n",
    "    resume_from_checkpoint=None,\n",
    "    accelerator='dp'\n",
    ")\n",
    "# config\n",
    "# https://wandb.ai/wandb/wandb-lightning/reports/Multi-GPU-Training-Using-PyTorch-Lightning--VmlldzozMTk3NTk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-india",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-761434b8d22d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Run inference on the images shown before\n",
    "\n",
    "logits = model(batch_train[\"image\"].to(model.device))\n",
    "print(f\"Shape of logits: {logits.shape}\")\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "print(f\"Shape of probs: {probs.shape}\")\n",
    "prediction = torch.argmax(probs, dim=1).long().cpu()\n",
    "print(f\"Shape of prediction: {prediction.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images=10\n",
    "fig, axs = plt.subplots(4, n_images, figsize=(18,14),tight_layout=True)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],axs=axs[0],max_clip_val=3500.)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],bands_show=[\"B11\",\"B8\", \"B4\"],\n",
    "                             axs=axs[1],max_clip_val=4500.)\n",
    "flooding_model.plot_batch_output_v1(batch_train[\"mask\"][:n_images, 0],axs=axs[2], show_axis=True)\n",
    "flooding_model.plot_batch_output_v1(prediction[:n_images] + 1,axs=axs[3], show_axis=True)\n",
    "\n",
    "for ax in axs.ravel():\n",
    "    ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model_params.max_tile_size = config.model_params.hyperparameters.max_tile_size\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from ml4floods.models.utils import metrics\n",
    "from ml4floods.models.model_setup import get_model_inference_function\n",
    "import pandas as pd\n",
    "\n",
    "# model.to(\"cuda\")\n",
    "inference_function = get_model_inference_function(model, config, apply_normalization=False, activation=\"softmax\")\n",
    "\n",
    "# config.data_params.batch_size = 8\n",
    "# dataset2 = get_dataset(config.data_params)\n",
    "dl = dataset.val_dataloader() # pytorch Dataloader\n",
    "print(str(dl.batch_size))\n",
    "\n",
    "# Otherwise fails when reading test dataset from remote bucket\n",
    "# torch.set_num_threads(1)\n",
    "\n",
    "thresholds_water = [0,1e-3,1e-2]+np.arange(0.5,.96,.05).tolist() + [.99,.995,.999]\n",
    "\n",
    "mets = metrics.compute_metrics(\n",
    "    dl,\n",
    "    inference_function, \n",
    "    thresholds_water=thresholds_water, \n",
    "    plot=False)\n",
    "\n",
    "label_names = [\"land\", \"water\", \"cloud\"]\n",
    "metrics.plot_metrics(mets, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(dl.dataset, \"image_files\"):\n",
    "    cems_code = [os.path.basename(f).split(\"_\")[0] for f in dl.dataset.image_files]\n",
    "else:\n",
    "    cems_code = [os.path.basename(f.file_name).split(\"_\")[0] for f in dl.dataset.list_of_windows]\n",
    "\n",
    "iou_per_code = pd.DataFrame(metrics.group_confusion(mets[\"confusions\"],cems_code, metrics.calculate_iou,\n",
    "                                                    label_names=[f\"IoU_{l}\"for l in [\"land\", \"water\", \"cloud\"]]))\n",
    "\n",
    "recall_per_code = pd.DataFrame(metrics.group_confusion(mets[\"confusions\"],cems_code, metrics.calculate_recall,\n",
    "                                                       label_names=[f\"Recall_{l}\"for l in [\"land\", \"water\", \"cloud\"]]))\n",
    "\n",
    "join_data_per_code = pd.merge(recall_per_code,iou_per_code,on=\"code\")\n",
    "join_data_per_code = join_data_per_code.set_index(\"code\")\n",
    "join_data_per_code = join_data_per_code*100\n",
    "print(f\"Mean values across flood events: {join_data_per_code.mean(axis=0).to_dict()}\")\n",
    "join_data_per_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_lightning.utilities.cloud_io import atomic_save\n",
    "from ml4floods.models.config_setup import save_json\n",
    "\n",
    "# Save in the cloud and in the wandb logger save dir\n",
    "atomic_save(model.state_dict(), f\"{experiment_path}/model.pt\")\n",
    "# Save cofig file in experiment_path\n",
    "config_file_path = f\"{experiment_path}/config.json\"\n",
    "save_json(config, config_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-consumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "if setup_weights_and_biases:\n",
    "    torch.save(model.state_dict(), os.path.join(wandb_logger.save_dir, 'model.pt'))\n",
    "    wandb.save(os.path.join(wandb_logger.save_dir, 'model.pt')) # Copy weights to weights and biases server\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-present",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt-gpu",
   "language": "python",
   "name": "pt-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
