{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "early-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4,5,6,7\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-history",
   "metadata": {},
   "source": [
    "## Load flooding configuration file from local device or gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "toxic-watch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Config for experiment:  worldfloods_demo_test\n",
      "{   'data_params': {   'batch_size': 32,\n",
      "                       'bucket_id': 'ml4cc_data_lake',\n",
      "                       'channel_configuration': 'all',\n",
      "                       'download': {'test': True, 'train': True, 'val': True},\n",
      "                       'filter_windows': {   'apply': False,\n",
      "                                             'threshold_clouds': 0.5,\n",
      "                                             'version': 'v1'},\n",
      "                       'input_folder': 'S2',\n",
      "                       'loader_type': 'local',\n",
      "                       'num_workers': 4,\n",
      "                       'path_to_splits': 'worldfloods',\n",
      "                       'target_folder': 'gt',\n",
      "                       'test_transformation': {'normalize': True},\n",
      "                       'train_test_split_file': '2_PROD/2_Mart/worldfloods_v1_0/train_test_split.json',\n",
      "                       'train_transformation': {'normalize': True},\n",
      "                       'window_size': [256, 256]},\n",
      "    'deploy': False,\n",
      "    'experiment_name': 'worldfloods_demo_test',\n",
      "    'gpus': '0',\n",
      "    'model_params': {   'hyperparameters': {   'channel_configuration': 'all',\n",
      "                                               'early_stopping_patience': 4,\n",
      "                                               'label_names': [   'land',\n",
      "                                                                  'water',\n",
      "                                                                  'cloud'],\n",
      "                                               'lr': 0.0001,\n",
      "                                               'lr_decay': 0.5,\n",
      "                                               'lr_patience': 2,\n",
      "                                               'max_epochs': 10,\n",
      "                                               'max_tile_size': 256,\n",
      "                                               'metric_monitor': 'val_dice_loss',\n",
      "                                               'model_type': 'linear',\n",
      "                                               'num_channels': 13,\n",
      "                                               'num_classes': 3,\n",
      "                                               'val_every': 1,\n",
      "                                               'weight_per_class': [   1.93445299,\n",
      "                                                                       36.60054169,\n",
      "                                                                       2.19400729]},\n",
      "                        'model_folder': 'gs://ml4cc_data_lake/0_DEV/2_Mart/2_MLModelMart',\n",
      "                        'model_version': 'v1',\n",
      "                        'test': True,\n",
      "                        'train': True},\n",
      "    'resume_from_checkpoint': False,\n",
      "    'seed': 12,\n",
      "    'test': False,\n",
      "    'train': False}\n"
     ]
    }
   ],
   "source": [
    "from ml4floods.models.config_setup import get_default_config\n",
    "import pkg_resources\n",
    "\n",
    "# Set filepath to configuration files\n",
    "# config_fp = 'path/to/worldfloods_template.json'\n",
    "config_fp = pkg_resources.resource_filename(\"ml4floods\",\"models/configurations/worldfloods_template.json\")\n",
    "\n",
    "config = get_default_config(config_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-scope",
   "metadata": {},
   "source": [
    "## Step 2: Setup Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defined-edgar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiment_name': 'training_flooding_rgb',\n",
       " 'seed': 12,\n",
       " 'model_params': {'model_folder': 'gs://ml4cc_data_lake/0_DEV/2_Mart/2_MLModelMart',\n",
       "  'model_version': 'v1',\n",
       "  'hyperparameters': {'max_tile_size': 256,\n",
       "   'metric_monitor': 'val_dice_loss',\n",
       "   'channel_configuration': 'rgb',\n",
       "   'label_names': ['land', 'water', 'cloud'],\n",
       "   'weight_per_class': [1.93445299, 36.60054169, 2.19400729],\n",
       "   'model_type': 'linear',\n",
       "   'num_classes': 3,\n",
       "   'max_epochs': 10,\n",
       "   'val_every': 1,\n",
       "   'lr': 0.0001,\n",
       "   'lr_decay': 0.5,\n",
       "   'lr_patience': 2,\n",
       "   'early_stopping_patience': 4,\n",
       "   'num_channels': 3},\n",
       "  'train': True,\n",
       "  'test': True},\n",
       " 'data_params': {'loader_type': 'local',\n",
       "  'num_workers': 4,\n",
       "  'filter_windows': {'version': 'v1', 'threshold_clouds': 0.5, 'apply': False},\n",
       "  'download': {'train': True, 'val': True, 'test': True},\n",
       "  'bucket_id': '',\n",
       "  'path_to_splits': 'worldfloods',\n",
       "  'train_test_split_file': '2_PROD/2_Mart/worldfloods_v1_0/train_test_split.json',\n",
       "  'input_folder': 'S2',\n",
       "  'target_folder': 'gt',\n",
       "  'batch_size': 48,\n",
       "  'window_size': [256, 256],\n",
       "  'channel_configuration': 'rgb',\n",
       "  'train_transformation': {'normalize': True},\n",
       "  'test_transformation': {'normalize': True}},\n",
       " 'resume_from_checkpoint': False,\n",
       " 'train': False,\n",
       " 'gpus': '0',\n",
       " 'test': False,\n",
       " 'deploy': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config.experiment_name = 'training_flooding_rgb_full_UNET'\n",
    "# config.data_params.channel_configuration = 'rgb'\n",
    "# config.data_params.window_size = [572,572]\n",
    "# config.data_params.batch_size = 48\n",
    "config.experiment_name = 'training_flooding_rgb'\n",
    "config.data_params.channel_configuration = 'rgb'\n",
    "config.data_params.window_size = [256,256]\n",
    "config.data_params.batch_size = 48\n",
    "config.model_params.hyperparameters.channel_configuration = 'rgb'\n",
    "config.model_params.hyperparameters.num_channels = 3\n",
    "config.data_params.bucket_id = \"\"\n",
    "config.data_params.num_workers = 4\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "scientific-musician",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local dataset for this run\n",
      "Downloading /mnt/d/Flooding/worldfloods_v1_sample/train/S2 if needed\n",
      "Downloading /mnt/d/Flooding/worldfloods_v1_sample/train/gt if needed\n",
      "Downloading /mnt/d/Flooding/worldfloods_v1_sample/test/S2 if needed\n",
      "Downloading /mnt/d/Flooding/worldfloods_v1_sample/test/gt if needed\n",
      "Downloading /mnt/d/Flooding/worldfloods_v1_sample/val/S2 if needed\n",
      "Downloading /mnt/d/Flooding/worldfloods_v1_sample/val/gt if needed\n",
      "train 194151  tiles\n",
      "val 1284  tiles\n",
      "test 11  tiles\n",
      "CPU times: user 5.9 s, sys: 3.35 s, total: 9.24 s\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from ml4floods.models.dataset_setup import get_dataset\n",
    "\n",
    "# config.data_params.batch_size = 96 # control this depending on the space on your GPU!\n",
    "config.data_params.loader_type = 'local'\n",
    "config.data_params.path_to_splits = \"/mnt/d/Flooding/worldfloods_v1_sample\" # local folder to download the data\n",
    "config.data_params.train_test_split_file = \"/mnt/d/Flooding/train_test_split.json\"\n",
    "\n",
    "config.data_params[\"download\"] = {\"train\": True, \"val\": True, \"test\": True} # download only test data\n",
    "# config.data_params.train_test_split_file = \"2_PROD/2_Mart/worldfloods_v1_0/train_test_split.json\" # use this to train with all the data\n",
    "\n",
    "# If files are not in config.data_params.path_to_splits this will trigger the download of the products.\n",
    "dataset = get_dataset(config.data_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-harassment",
   "metadata": {},
   "source": [
    "## Verfify data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-driver",
   "metadata": {},
   "source": [
    "#### Verify training data\n",
    "Data format here: https://github.com/spaceml-org/ml4floods/blob/891fe602880586e7ac821d2f282bf5ec9d4c0795/ml4floods/data/worldfloods/dataset.py#L106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fallen-harbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4045\n"
     ]
    }
   ],
   "source": [
    "train_dl = dataset.train_dataloader()\n",
    "train_dl_iter = iter(train_dl)\n",
    "print(len(train_dl_iter))\n",
    "batch_train = next(train_dl_iter)\n",
    "\n",
    "# batch_train[\"image\"].shape, batch_train[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-spanking",
   "metadata": {},
   "source": [
    "Verify validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "injured-effect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "val_dl = dataset.val_dataloader()\n",
    "\n",
    "val_dl_iter = iter(val_dl)\n",
    "print(len(val_dl_iter))\n",
    "batch_val = next(val_dl_iter)\n",
    "\n",
    "# batch_val[\"image\"].shape, batch_val[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "significant-multiple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "test_dl = dataset.test_dataloader()\n",
    "\n",
    "test_dl_iter = iter(test_dl)\n",
    "print(len(test_dl_iter))\n",
    "\n",
    "batch_test = next(test_dl_iter)\n",
    "# batch_test[\"image\"].shape, batch_test[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-electron",
   "metadata": {},
   "source": [
    "### Plot batch by using ml4flood model \n",
    "check detail here: https://github.com/spaceml-org/ml4floods/blob/891fe602880586e7ac821d2f282bf5ec9d4c0795/ml4floods/data/worldfloods/dataset.py#L106"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bridal-needle",
   "metadata": {},
   "source": [
    "from models import flooding_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "flooding_model.plot_batch(batch_train[\"image\"])\n",
    "\n",
    "n_images=6\n",
    "fig, axs = plt.subplots(3,n_images, figsize=(18,10),tight_layout=True)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],axs=axs[0],max_clip_val=3500.)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],bands_show=[\"B11\",\"B8\", \"B4\"],\n",
    "                             axs=axs[1],max_clip_val=4500.)\n",
    "flooding_model.plot_batch_output_v1(batch_train[\"mask\"][:n_images, 0],axs=axs[2], show_axis=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7279717-cfb1-4d20-a915-869d1ab3ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "from models import flooding_model\n",
    "flooding_model = importlib.reload(flooding_model)\n",
    "\n",
    "# batch_train_rgb = flooding_model.batch_to_unnorm_rgb(batch_train[\"image\"])\n",
    "# # batch_train_rgb.shape\n",
    "# plt.imshow(batch_train_rgb[2])\n",
    "# plt.show()\n",
    "\n",
    "# batch_train_rgb_mask = flooding_model.batch_mask_to_rgb(batch_train[\"mask\"])\n",
    "# plt.imshow(batch_train_rgb_mask[2])\n",
    "# plt.colorbar()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-cleanup",
   "metadata": {},
   "source": [
    "## Step 3: Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "proud-surrey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_folder': 'gs://ml4cc_data_lake/0_DEV/2_Mart/2_MLModelMart',\n",
       " 'model_version': 'v1',\n",
       " 'hyperparameters': {'max_tile_size': 256,\n",
       "  'metric_monitor': 'val_dice_loss',\n",
       "  'channel_configuration': 'rgb',\n",
       "  'label_names': ['land', 'water', 'cloud'],\n",
       "  'weight_per_class': [1.93445299, 36.60054169, 2.19400729],\n",
       "  'model_type': 'linear',\n",
       "  'num_classes': 3,\n",
       "  'max_epochs': 10,\n",
       "  'val_every': 1,\n",
       "  'lr': 0.0001,\n",
       "  'lr_decay': 0.5,\n",
       "  'lr_patience': 2,\n",
       "  'early_stopping_patience': 4,\n",
       "  'num_channels': 3},\n",
       " 'train': True,\n",
       " 'test': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # folder to store the trained model (it will create a subfolder with the name of the experiment)\n",
    "config.model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "colonial-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model_params.model_folder = \"train_models\" \n",
    "os.makedirs(\"train_models\", exist_ok=True)\n",
    "config.model_params.test = False\n",
    "config.model_params.train = True\n",
    "config.model_params.hyperparameters.model_type = \"unet\" # Currently implemented: simplecnn, unet, linear, full_unet\n",
    "# config.model_params.hyperparameters.max_tile_size = 572\n",
    "config.model_params.hyperparameters.max_tile_size = 256\n",
    "# config.model_params.hyperparameters.num_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alternative-bonus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of channels:  3 , num of classes:  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (dconv_down1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_down2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_down3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_down4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dconv_up3): Sequential(\n",
       "    (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_up2): Sequential(\n",
       "    (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_up1): Sequential(\n",
       "    (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_last): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "from models.flooding_model import WorldFloodsModel, DistilledTrainingModel\n",
    "importlib.reload(flooding_model)\n",
    "simple_model_params = copy.deepcopy(config.model_params)\n",
    "# simple_model_params['hyperparameters']['model_type']=\"full_unet\"\n",
    "\n",
    "# model = DistilledTrainingModel(config.model_params, simple_model_params)\n",
    "model = WorldFloodsModel(config.model_params)\n",
    "net = model.network\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd551674-c867-4590-b1c2-0bbb39d98f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module UNet is treated as a zero-op.\n",
      "UNet(\n",
      "  7.783 M, 100.000% Params, 42.473 GMac, 100.000% MACs, \n",
      "  (dconv_down1): Sequential(\n",
      "    0.039 M, 0.497% Params, 2.546 GMac, 5.994% MACs, \n",
      "    (0): Conv2d(0.002 M, 0.023% Params, 0.117 GMac, 0.277% MACs, 3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.010% MACs, inplace=True)\n",
      "    (2): Conv2d(0.037 M, 0.474% Params, 2.42 GMac, 5.698% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.010% MACs, inplace=True)\n",
      "  )\n",
      "  (dconv_down2): Sequential(\n",
      "    0.221 M, 2.845% Params, 3.632 GMac, 8.552% MACs, \n",
      "    (0): Conv2d(0.074 M, 0.949% Params, 1.21 GMac, 2.849% MACs, 64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.005% MACs, inplace=True)\n",
      "    (2): Conv2d(0.148 M, 1.896% Params, 2.418 GMac, 5.693% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.005% MACs, inplace=True)\n",
      "  )\n",
      "  (dconv_down3): Sequential(\n",
      "    0.885 M, 11.374% Params, 3.628 GMac, 8.542% MACs, \n",
      "    (0): Conv2d(0.295 M, 3.792% Params, 1.209 GMac, 2.847% MACs, 128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "    (2): Conv2d(0.59 M, 7.582% Params, 2.417 GMac, 5.691% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "  )\n",
      "  (dconv_down4): Sequential(\n",
      "    3.54 M, 45.483% Params, 3.626 GMac, 8.537% MACs, \n",
      "    (0): Conv2d(1.18 M, 15.163% Params, 1.208 GMac, 2.845% MACs, 256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "    (2): Conv2d(2.36 M, 30.320% Params, 2.416 GMac, 5.689% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "  )\n",
      "  (maxpool): MaxPool2d(0.0 M, 0.000% Params, 0.007 GMac, 0.017% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dconv_up3): Sequential(\n",
      "    2.36 M, 30.320% Params, 9.668 GMac, 22.763% MACs, \n",
      "    (0): Conv2d(1.77 M, 22.738% Params, 7.249 GMac, 17.067% MACs, 768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "    (2): Conv2d(0.59 M, 7.582% Params, 2.417 GMac, 5.691% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "  )\n",
      "  (dconv_up2): Sequential(\n",
      "    0.59 M, 7.582% Params, 9.672 GMac, 22.772% MACs, \n",
      "    (0): Conv2d(0.442 M, 5.685% Params, 7.25 GMac, 17.069% MACs, 384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.005% MACs, inplace=True)\n",
      "    (2): Conv2d(0.148 M, 1.896% Params, 2.418 GMac, 5.693% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.005% MACs, inplace=True)\n",
      "  )\n",
      "  (dconv_up1): Sequential(\n",
      "    0.148 M, 1.896% Params, 9.68 GMac, 22.792% MACs, \n",
      "    (0): Conv2d(0.111 M, 1.422% Params, 7.252 GMac, 17.074% MACs, 192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.010% MACs, inplace=True)\n",
      "    (2): Conv2d(0.037 M, 0.474% Params, 2.42 GMac, 5.698% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.010% MACs, inplace=True)\n",
      "  )\n",
      "  (conv_last): Conv2d(0.0 M, 0.003% Params, 0.013 GMac, 0.030% MACs, 64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Computational complexity:       42.47 GMac\n",
      "Number of parameters:           7.78 M  \n"
     ]
    }
   ],
   "source": [
    "# Compuatation complexity of network\n",
    "from ptflops import get_model_complexity_info\n",
    "macs, params = get_model_complexity_info(net, (config.model_params.hyperparameters.num_channels, config.model_params.hyperparameters.max_tile_size, config.model_params.hyperparameters.max_tile_size), as_strings=True, print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "seventh-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_weights_and_biases = False\n",
    "if setup_weights_and_biases:\n",
    "    import wandb\n",
    "    from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "    # UNCOMMENT ON FIRST RUN TO LOGIN TO Weights and Biases (only needs to be done once)\n",
    "    # wandb.login()\n",
    "    # run = wandb.init()\n",
    "\n",
    "    # Specifies who is logging the experiment to wandb\n",
    "    config['wandb_entity'] = 'ml4floods'\n",
    "    # Specifies which wandb project to log to, multiple runs can exist in the same project\n",
    "    config['wandb_project'] = 'worldfloods-notebook-demo-project'\n",
    "\n",
    "    wandb_logger = WandbLogger(\n",
    "        name=config.experiment_name,\n",
    "        project=config.wandb_project, \n",
    "        entity=config.wandb_entity\n",
    "    )\n",
    "else:\n",
    "    wandb_logger = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "downtown-teens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trained model will be stored in train_models/training_flooding_rgb\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "experiment_path = f\"{config.model_params.model_folder}/{config.experiment_name}\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"{experiment_path}/checkpoint\",\n",
    "    save_top_k=True,\n",
    "    verbose=True,\n",
    "    monitor='val_dice_loss',\n",
    "    mode='min',\n",
    "#     prefix=''\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_dice_loss',\n",
    "    patience=10,\n",
    "    strict=False,\n",
    "    verbose=False,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint_callback, early_stop_callback]\n",
    "\n",
    "print(f\"The trained model will be stored in {config.model_params.model_folder}/{config.experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "searching-charity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "config.gpus = 4 # which gpu to use\n",
    "\n",
    "# config.gpus = None # to not use GPU\n",
    "\n",
    "config.model_params.hyperparameters.max_epochs = 40 # train for maximum 4 epochs\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     fast_dev_run=False,\n",
    "#     logger=wandb_logger,\n",
    "#     callbacks=callbacks,\n",
    "#     default_root_dir=f\"{config.model_params.model_folder}/{config.experiment_name}\",\n",
    "#     accumulate_grad_batches=1,\n",
    "#     gradient_clip_val=0.0,\n",
    "#     auto_lr_find=False,\n",
    "#     benchmark=False,\n",
    "#     distributed_backend=None,\n",
    "#     gpus=config.gpus,\n",
    "#     max_epochs=config.model_params.hyperparameters.max_epochs,\n",
    "#     check_val_every_n_epoch=config.model_params.hyperparameters.val_every,\n",
    "#     log_gpu_memory=False,\n",
    "#     resume_from_checkpoint='./train_models/training_flooding_rgb/checkpoint/epoch=29-step=182039.ckpt',\n",
    "#     accelerator='dp'\n",
    "# )\n",
    "\n",
    "trainer = Trainer(\n",
    "    fast_dev_run=False,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=callbacks,\n",
    "    default_root_dir=f\"{config.model_params.model_folder}/{config.experiment_name}\",\n",
    "    accumulate_grad_batches=1,\n",
    "    gradient_clip_val=0.0,\n",
    "    auto_lr_find=False,\n",
    "    benchmark=False,\n",
    "    distributed_backend=None,\n",
    "    gpus=config.gpus,\n",
    "    max_epochs=config.model_params.hyperparameters.max_epochs,\n",
    "    check_val_every_n_epoch=config.model_params.hyperparameters.val_every,\n",
    "    log_gpu_memory=False,\n",
    "    accelerator='dp'\n",
    ")\n",
    "# config\n",
    "# https://wandb.ai/wandb/wandb-lightning/reports/Multi-GPU-Training-Using-PyTorch-Lightning--VmlldzozMTk3NTk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-india",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [4,5,6,7]\n",
      "\n",
      "  | Name    | Type | Params\n",
      "---------------------------------\n",
      "0 | network | UNet | 7.8 M \n",
      "---------------------------------\n",
      "7.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.8 M     Total params\n",
      "31.132    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeaiserver/pt-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23249149b07436e9d5a1f0f1312ad8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 4044: val_dice_loss reached 0.68704 (best 0.68704), saving model to \"/home/eeaiserver/viplab_projects/satellite-knowledge-distillation/train_models/training_flooding_rgb/checkpoint/epoch=0-step=4044.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 8089: val_dice_loss reached 0.64631 (best 0.64631), saving model to \"/home/eeaiserver/viplab_projects/satellite-knowledge-distillation/train_models/training_flooding_rgb/checkpoint/epoch=1-step=8089.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 12134: val_dice_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 16179: val_dice_loss reached 0.50446 (best 0.50446), saving model to \"/home/eeaiserver/viplab_projects/satellite-knowledge-distillation/train_models/training_flooding_rgb/checkpoint/epoch=3-step=16179.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 20224: val_dice_loss reached 0.43789 (best 0.43789), saving model to \"/home/eeaiserver/viplab_projects/satellite-knowledge-distillation/train_models/training_flooding_rgb/checkpoint/epoch=4-step=20224.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 24269: val_dice_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 28314: val_dice_loss reached 0.42891 (best 0.42891), saving model to \"/home/eeaiserver/viplab_projects/satellite-knowledge-distillation/train_models/training_flooding_rgb/checkpoint/epoch=6-step=28314.ckpt\" as top True\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Run inference on the images shown before\n",
    "\n",
    "logits = model(batch_train[\"image\"].to(model.device))\n",
    "print(f\"Shape of logits: {logits.shape}\")\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "print(f\"Shape of probs: {probs.shape}\")\n",
    "prediction = torch.argmax(probs, dim=1).long().cpu()\n",
    "print(f\"Shape of prediction: {prediction.shape}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3eb6095c-4b3f-47db-8920-92242e50f36b",
   "metadata": {},
   "source": [
    "n_images=10\n",
    "fig, axs = plt.subplots(4, n_images, figsize=(18,14),tight_layout=True)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],axs=axs[0],max_clip_val=3500.)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],bands_show=[\"B11\",\"B8\", \"B4\"],\n",
    "                             axs=axs[1],max_clip_val=4500.)\n",
    "flooding_model.plot_batch_output_v1(batch_train[\"mask\"][:n_images, 0],axs=axs[2], show_axis=True)\n",
    "flooding_model.plot_batch_output_v1(prediction[:n_images] + 1,axs=axs[3], show_axis=True)\n",
    "\n",
    "for ax in axs.ravel():\n",
    "    ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model_params.max_tile_size = config.model_params.hyperparameters.max_tile_size\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from ml4floods.models.utils import metrics\n",
    "from ml4floods.models.model_setup import get_model_inference_function\n",
    "import pandas as pd\n",
    "\n",
    "# model.to(\"cuda\")\n",
    "inference_function = get_model_inference_function(model, config, apply_normalization=False, activation=\"softmax\")\n",
    "\n",
    "config.data_params.batch_size = 8\n",
    "# print(config.data_params)\n",
    "# dataset2 = get_dataset(config.data_params)\n",
    "dl = dataset.val_dataloader() # pytorch Dataloader\n",
    "print(str(dl.batch_size))\n",
    "\n",
    "# Otherwise fails when reading test dataset from remote bucket\n",
    "# torch.set_num_threads(1)\n",
    "\n",
    "thresholds_water = [0,1e-3,1e-2]+np.arange(0.5,.96,.05).tolist() + [.99,.995,.999]\n",
    "\n",
    "mets = metrics.compute_metrics(\n",
    "    dl,\n",
    "    inference_function, \n",
    "    thresholds_water=thresholds_water, \n",
    "    plot=False)\n",
    "\n",
    "label_names = [\"land\", \"water\", \"cloud\"]\n",
    "metrics.plot_metrics(mets, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(dl.dataset, \"image_files\"):\n",
    "    cems_code = [os.path.basename(f).split(\"_\")[0] for f in dl.dataset.image_files]\n",
    "else:\n",
    "    cems_code = [os.path.basename(f.file_name).split(\"_\")[0] for f in dl.dataset.list_of_windows]\n",
    "\n",
    "iou_per_code = pd.DataFrame(metrics.group_confusion(mets[\"confusions\"],cems_code, metrics.calculate_iou,\n",
    "                                                    label_names=[f\"IoU_{l}\"for l in [\"land\", \"water\", \"cloud\"]]))\n",
    "\n",
    "recall_per_code = pd.DataFrame(metrics.group_confusion(mets[\"confusions\"],cems_code, metrics.calculate_recall,\n",
    "                                                       label_names=[f\"Recall_{l}\"for l in [\"land\", \"water\", \"cloud\"]]))\n",
    "\n",
    "join_data_per_code = pd.merge(recall_per_code,iou_per_code,on=\"code\")\n",
    "join_data_per_code = join_data_per_code.set_index(\"code\")\n",
    "join_data_per_code = join_data_per_code*100\n",
    "print(f\"Mean values across flood events: {join_data_per_code.mean(axis=0).to_dict()}\")\n",
    "join_data_per_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_lightning.utilities.cloud_io import atomic_save\n",
    "from ml4floods.models.config_setup import save_json\n",
    "\n",
    "# Save in the cloud and in the wandb logger save dir\n",
    "atomic_save(model.state_dict(), f\"{experiment_path}/model_rgb_unet_epoch_40.pt\")\n",
    "# Save cofig file in experiment_path\n",
    "config_file_path = f\"{experiment_path}/config_rgb_epoch_30.json\"\n",
    "save_json(config, config_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-consumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "if setup_weights_and_biases:\n",
    "    torch.save(model.state_dict(), os.path.join(wandb_logger.save_dir, 'model_rgb_unet_epoch_40.pt'))\n",
    "    wandb.save(os.path.join(wandb_logger.save_dir, 'model_rgb_full_unet_epoch_4.pt')) # Copy weights to weights and biases server\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c92b73-fb5e-4d45-890e-fcd48fa145e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on the images shown before\n",
    "\n",
    "logits = model(batch_val[\"image\"].to(model.device))\n",
    "print(f\"Shape of logits: {logits.shape}\")\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "print(f\"Shape of probs: {probs.shape}\")\n",
    "prediction = torch.argmax(probs, dim=1).long().cpu()\n",
    "print(f\"Shape of prediction: {prediction.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605531f6-e860-46bb-98ce-185767539a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_image_start=0\n",
    "n_images=4\n",
    "count=int(n_images-n_image_start)\n",
    "fig, axs = plt.subplots(4, count, figsize=(18,14),tight_layout=True)\n",
    "importlib.reload(flooding_model)\n",
    "flooding_model.plot_batch(batch_val[\"image\"][n_image_start:n_images],channel_configuration=\"rgb\",axs=axs[0],max_clip_val=3500.)\n",
    "# flooding_model.plot_batch(batch_val[\"image\"][n_image_start:n_images],channel_configuration=\"bgri\",bands_show=[\"B8\",\"B8\", \"B8\"],axs=axs[1],max_clip_val=3500.)\n",
    "# flooding_model.plot_batch(batch_val[\"image\"][:n_images],bands_show=[\"B11\",\"B8\", \"B4\"],axs=axs[1],max_clip_val=4500.)\n",
    "flooding_model.plot_batch_output_v1(batch_val[\"mask\"][n_image_start:n_images, 0],axs=axs[2], show_axis=True)\n",
    "flooding_model.plot_batch_output_v1(prediction[n_image_start:n_images] + 1,axs=axs[3], show_axis=True)\n",
    "\n",
    "for ax in axs.ravel():\n",
    "    ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e328ef75-eee4-4c24-85f7-c24ea9af3b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt-gpu",
   "language": "python",
   "name": "pt-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
