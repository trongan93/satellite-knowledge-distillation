{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "early-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2,3,4,5,6,7\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-history",
   "metadata": {},
   "source": [
    "## Load flooding configuration file from local device or gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "toxic-watch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Config for experiment:  worldfloods_demo_test\n",
      "{   'data_params': {   'batch_size': 32,\n",
      "                       'bucket_id': 'ml4cc_data_lake',\n",
      "                       'channel_configuration': 'all',\n",
      "                       'download': {'test': True, 'train': True, 'val': True},\n",
      "                       'filter_windows': {   'apply': False,\n",
      "                                             'threshold_clouds': 0.5,\n",
      "                                             'version': 'v1'},\n",
      "                       'input_folder': 'S2',\n",
      "                       'loader_type': 'local',\n",
      "                       'num_workers': 4,\n",
      "                       'path_to_splits': 'worldfloods',\n",
      "                       'target_folder': 'gt',\n",
      "                       'test_transformation': {'normalize': True},\n",
      "                       'train_test_split_file': '2_PROD/2_Mart/worldfloods_v1_0/train_test_split.json',\n",
      "                       'train_transformation': {'normalize': True},\n",
      "                       'window_size': [256, 256]},\n",
      "    'deploy': False,\n",
      "    'experiment_name': 'worldfloods_demo_test',\n",
      "    'gpus': '0',\n",
      "    'model_params': {   'hyperparameters': {   'channel_configuration': 'all',\n",
      "                                               'early_stopping_patience': 4,\n",
      "                                               'label_names': [   'land',\n",
      "                                                                  'water',\n",
      "                                                                  'cloud'],\n",
      "                                               'lr': 0.0001,\n",
      "                                               'lr_decay': 0.5,\n",
      "                                               'lr_patience': 2,\n",
      "                                               'max_epochs': 10,\n",
      "                                               'max_tile_size': 256,\n",
      "                                               'metric_monitor': 'val_dice_loss',\n",
      "                                               'model_type': 'linear',\n",
      "                                               'num_channels': 13,\n",
      "                                               'num_classes': 3,\n",
      "                                               'val_every': 1,\n",
      "                                               'weight_per_class': [   1.93445299,\n",
      "                                                                       36.60054169,\n",
      "                                                                       2.19400729]},\n",
      "                        'model_folder': 'gs://ml4cc_data_lake/0_DEV/2_Mart/2_MLModelMart',\n",
      "                        'model_version': 'v1',\n",
      "                        'test': True,\n",
      "                        'train': True},\n",
      "    'resume_from_checkpoint': False,\n",
      "    'seed': 12,\n",
      "    'test': False,\n",
      "    'train': False}\n"
     ]
    }
   ],
   "source": [
    "from ml4floods.models.config_setup import get_default_config\n",
    "import pkg_resources\n",
    "\n",
    "# Set filepath to configuration files\n",
    "# config_fp = 'path/to/worldfloods_template.json'\n",
    "config_fp = pkg_resources.resource_filename(\"ml4floods\",\"models/configurations/worldfloods_template.json\")\n",
    "\n",
    "config = get_default_config(config_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-scope",
   "metadata": {},
   "source": [
    "## Step 2: Setup Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defined-edgar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiment_name': 'training_flooding',\n",
       " 'seed': 12,\n",
       " 'model_params': {'model_folder': 'gs://ml4cc_data_lake/0_DEV/2_Mart/2_MLModelMart',\n",
       "  'model_version': 'v1',\n",
       "  'hyperparameters': {'max_tile_size': 256,\n",
       "   'metric_monitor': 'val_dice_loss',\n",
       "   'channel_configuration': 'rgb',\n",
       "   'label_names': ['land', 'water', 'cloud'],\n",
       "   'weight_per_class': [1.93445299, 36.60054169, 2.19400729],\n",
       "   'model_type': 'linear',\n",
       "   'num_classes': 3,\n",
       "   'max_epochs': 10,\n",
       "   'val_every': 1,\n",
       "   'lr': 0.0001,\n",
       "   'lr_decay': 0.5,\n",
       "   'lr_patience': 2,\n",
       "   'early_stopping_patience': 4,\n",
       "   'num_channels': 3},\n",
       "  'train': True,\n",
       "  'test': True},\n",
       " 'data_params': {'loader_type': 'local',\n",
       "  'num_workers': 4,\n",
       "  'filter_windows': {'version': 'v1', 'threshold_clouds': 0.5, 'apply': False},\n",
       "  'download': {'train': True, 'val': True, 'test': True},\n",
       "  'bucket_id': 'ml4cc_data_lake',\n",
       "  'path_to_splits': 'worldfloods',\n",
       "  'train_test_split_file': '2_PROD/2_Mart/worldfloods_v1_0/train_test_split.json',\n",
       "  'input_folder': 'S2',\n",
       "  'target_folder': 'gt',\n",
       "  'batch_size': 32,\n",
       "  'window_size': [256, 256],\n",
       "  'channel_configuration': 'rgb',\n",
       "  'train_transformation': {'normalize': True},\n",
       "  'test_transformation': {'normalize': True}},\n",
       " 'resume_from_checkpoint': False,\n",
       " 'train': False,\n",
       " 'gpus': '0',\n",
       " 'test': False,\n",
       " 'deploy': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.experiment_name = 'training_flooding'\n",
    "config.data_params.channel_configuration = 'rgb'\n",
    "config.model_params.hyperparameters.channel_configuration = 'rgb'\n",
    "config.model_params.hyperparameters.num_channels = 3\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "scientific-musician",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local dataset for this run\n",
      "Downloading /mnt/d/Flooding/worldfloods_v1_sample/train/S2 if needed\n",
      "Downloading /mnt/d/Flooding/worldfloods_v1_sample/train/gt if needed\n",
      "Downloading /mnt/d/Flooding/worldfloods_v1_sample/test/S2 if needed\n",
      "Downloading /mnt/d/Flooding/worldfloods_v1_sample/test/gt if needed\n",
      "Downloading /mnt/d/Flooding/worldfloods_v1_sample/val/S2 if needed\n",
      "Downloading /mnt/d/Flooding/worldfloods_v1_sample/val/gt if needed\n",
      "train 194151  tiles\n",
      "val 1284  tiles\n",
      "test 11  tiles\n",
      "CPU times: user 4.95 s, sys: 2.99 s, total: 7.94 s\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from ml4floods.models.dataset_setup import get_dataset\n",
    "\n",
    "# config.data_params.batch_size = 96 # control this depending on the space on your GPU!\n",
    "config.data_params.loader_type = 'local'\n",
    "config.data_params.path_to_splits = \"/mnt/d/Flooding/worldfloods_v1_sample\" # local folder to download the data\n",
    "# config.data_params.train_test_split_file = \"2_PROD/2_Mart/worldfloods_v1_0/train_test_split_sample.json\"\n",
    "\n",
    "config.data_params[\"download\"] = {\"train\": True, \"val\": True, \"test\": True} # download only test data\n",
    "config.data_params.train_test_split_file = \"2_PROD/2_Mart/worldfloods_v1_0/train_test_split.json\" # use this to train with all the data\n",
    "config.data_params.num_workers = 7\n",
    "\n",
    "# If files are not in config.data_params.path_to_splits this will trigger the download of the products.\n",
    "dataset = get_dataset(config.data_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-harassment",
   "metadata": {},
   "source": [
    "## Verfify data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-driver",
   "metadata": {},
   "source": [
    "#### Verify training data\n",
    "Data format here: https://github.com/spaceml-org/ml4floods/blob/891fe602880586e7ac821d2f282bf5ec9d4c0795/ml4floods/data/worldfloods/dataset.py#L106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fallen-harbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6068\n"
     ]
    }
   ],
   "source": [
    "train_dl = dataset.train_dataloader()\n",
    "train_dl_iter = iter(train_dl)\n",
    "print(len(train_dl_iter))\n",
    "batch_train = next(train_dl_iter)\n",
    "\n",
    "# batch_train[\"image\"].shape, batch_train[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-spanking",
   "metadata": {},
   "source": [
    "Verify validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "injured-effect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "val_dl = dataset.val_dataloader()\n",
    "\n",
    "val_dl_iter = iter(val_dl)\n",
    "print(len(val_dl_iter))\n",
    "batch_val = next(val_dl_iter)\n",
    "\n",
    "# batch_val[\"image\"].shape, batch_val[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "significant-multiple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "test_dl = dataset.test_dataloader()\n",
    "\n",
    "test_dl_iter = iter(test_dl)\n",
    "print(len(test_dl_iter))\n",
    "\n",
    "batch_test = next(test_dl_iter)\n",
    "# batch_test[\"image\"].shape, batch_test[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-electron",
   "metadata": {},
   "source": [
    "### Plot batch by using ml4flood model \n",
    "check detail here: https://github.com/spaceml-org/ml4floods/blob/891fe602880586e7ac821d2f282bf5ec9d4c0795/ml4floods/data/worldfloods/dataset.py#L106"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bridal-needle",
   "metadata": {},
   "source": [
    "from models import flooding_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "flooding_model.plot_batch(batch_train[\"image\"])\n",
    "\n",
    "n_images=6\n",
    "fig, axs = plt.subplots(3,n_images, figsize=(18,10),tight_layout=True)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],axs=axs[0],max_clip_val=3500.)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],bands_show=[\"B11\",\"B8\", \"B4\"],\n",
    "                             axs=axs[1],max_clip_val=4500.)\n",
    "flooding_model.plot_batch_output_v1(batch_train[\"mask\"][:n_images, 0],axs=axs[2], show_axis=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7279717-cfb1-4d20-a915-869d1ab3ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "from models import flooding_model\n",
    "flooding_model = importlib.reload(flooding_model)\n",
    "\n",
    "# batch_train_rgb = flooding_model.batch_to_unnorm_rgb(batch_train[\"image\"])\n",
    "# # batch_train_rgb.shape\n",
    "# plt.imshow(batch_train_rgb[2])\n",
    "# plt.show()\n",
    "\n",
    "# batch_train_rgb_mask = flooding_model.batch_mask_to_rgb(batch_train[\"mask\"])\n",
    "# plt.imshow(batch_train_rgb_mask[2])\n",
    "# plt.colorbar()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-cleanup",
   "metadata": {},
   "source": [
    "## Step 3: Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "proud-surrey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_folder': 'gs://ml4cc_data_lake/0_DEV/2_Mart/2_MLModelMart',\n",
       " 'model_version': 'v1',\n",
       " 'hyperparameters': {'max_tile_size': 256,\n",
       "  'metric_monitor': 'val_dice_loss',\n",
       "  'channel_configuration': 'rgb',\n",
       "  'label_names': ['land', 'water', 'cloud'],\n",
       "  'weight_per_class': [1.93445299, 36.60054169, 2.19400729],\n",
       "  'model_type': 'linear',\n",
       "  'num_classes': 3,\n",
       "  'max_epochs': 10,\n",
       "  'val_every': 1,\n",
       "  'lr': 0.0001,\n",
       "  'lr_decay': 0.5,\n",
       "  'lr_patience': 2,\n",
       "  'early_stopping_patience': 4,\n",
       "  'num_channels': 3},\n",
       " 'train': True,\n",
       " 'test': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # folder to store the trained model (it will create a subfolder with the name of the experiment)\n",
    "config.model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "colonial-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model_params.model_folder = \"train_models\" \n",
    "os.makedirs(\"train_models\", exist_ok=True)\n",
    "config.model_params.test = False\n",
    "config.model_params.train = True\n",
    "config.model_params.hyperparameters.model_type = \"unet\" # Currently implemented: simplecnn, unet, linear\n",
    "# config.model_params.hyperparameters.num_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alternative-bonus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of channels:  3 , num of classes:  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WorldFloodsModel(\n",
       "  (network): UNet(\n",
       "    (dconv_down1): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (dconv_down2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (dconv_down3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (dconv_down4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (dconv_up3): Sequential(\n",
       "      (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (dconv_up2): Sequential(\n",
       "      (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (dconv_up1): Sequential(\n",
       "      (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv_last): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "from models.flooding_model import WorldFloodsModel, DistilledTrainingModel\n",
    "importlib.reload(flooding_model)\n",
    "simple_model_params = copy.deepcopy(config.model_params)\n",
    "simple_model_params['hyperparameters']['model_type']=\"unet_simple\"\n",
    "\n",
    "# model = DistilledTrainingModel(config.model_params, simple_model_params)\n",
    "model = WorldFloodsModel(config.model_params)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "seventh-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_weights_and_biases = False\n",
    "if setup_weights_and_biases:\n",
    "    import wandb\n",
    "    from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "    # UNCOMMENT ON FIRST RUN TO LOGIN TO Weights and Biases (only needs to be done once)\n",
    "    # wandb.login()\n",
    "    # run = wandb.init()\n",
    "\n",
    "    # Specifies who is logging the experiment to wandb\n",
    "    config['wandb_entity'] = 'ml4floods'\n",
    "    # Specifies which wandb project to log to, multiple runs can exist in the same project\n",
    "    config['wandb_project'] = 'worldfloods-notebook-demo-project'\n",
    "\n",
    "    wandb_logger = WandbLogger(\n",
    "        name=config.experiment_name,\n",
    "        project=config.wandb_project, \n",
    "        entity=config.wandb_entity\n",
    "    )\n",
    "else:\n",
    "    wandb_logger = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "downtown-teens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trained model will be stored in train_models/training_flooding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeaiserver/pt-gpu/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:360: UserWarning: Checkpoint directory train_models/training_flooding/checkpoint exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "experiment_path = f\"{config.model_params.model_folder}/{config.experiment_name}\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"{experiment_path}/checkpoint\",\n",
    "    save_top_k=True,\n",
    "    verbose=True,\n",
    "    monitor='val_dice_loss',\n",
    "    mode='min',\n",
    "#     prefix=''\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_dice_loss',\n",
    "    patience=10,\n",
    "    strict=False,\n",
    "    verbose=False,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint_callback, early_stop_callback]\n",
    "\n",
    "print(f\"The trained model will be stored in {config.model_params.model_folder}/{config.experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "searching-charity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "config.gpus = 7 # which gpu to use\n",
    "\n",
    "# config.gpus = None # to not use GPU\n",
    "\n",
    "config.model_params.hyperparameters.max_epochs = 5 # train for maximum 4 epochs\n",
    "\n",
    "trainer = Trainer(\n",
    "    fast_dev_run=False,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=callbacks,\n",
    "    default_root_dir=f\"{config.model_params.model_folder}/{config.experiment_name}\",\n",
    "    accumulate_grad_batches=1,\n",
    "    gradient_clip_val=0.0,\n",
    "    auto_lr_find=False,\n",
    "    benchmark=False,\n",
    "    distributed_backend=None,\n",
    "    gpus=config.gpus,\n",
    "    max_epochs=config.model_params.hyperparameters.max_epochs,\n",
    "    check_val_every_n_epoch=config.model_params.hyperparameters.val_every,\n",
    "    log_gpu_memory=False,\n",
    "    resume_from_checkpoint=None,\n",
    "    accelerator='dp'\n",
    ")\n",
    "# config\n",
    "# https://wandb.ai/wandb/wandb-lightning/reports/Multi-GPU-Training-Using-PyTorch-Lightning--VmlldzozMTk3NTk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "superior-india",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1,2,3,4,5,6,7]\n",
      "/home/eeaiserver/pt-gpu/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 3. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "\n",
      "  | Name    | Type | Params\n",
      "---------------------------------\n",
      "0 | network | UNet | 7.8 M \n",
      "---------------------------------\n",
      "7.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.8 M     Total params\n",
      "31.132    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeaiserver/pt-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19681ee1ae74563830f1fe48d7f9397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 6067: val_dice_loss reached 0.67523 (best 0.67523), saving model to \"/home/eeaiserver/viplab_projects/satellite-knowledge-distillation/train_models/training_flooding/checkpoint/epoch=0-step=6067-v2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 12135: val_dice_loss reached 0.65873 (best 0.65873), saving model to \"/home/eeaiserver/viplab_projects/satellite-knowledge-distillation/train_models/training_flooding/checkpoint/epoch=1-step=12135-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 18203: val_dice_loss reached 0.62000 (best 0.62000), saving model to \"/home/eeaiserver/viplab_projects/satellite-knowledge-distillation/train_models/training_flooding/checkpoint/epoch=2-step=18203.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 24271: val_dice_loss reached 0.46604 (best 0.46604), saving model to \"/home/eeaiserver/viplab_projects/satellite-knowledge-distillation/train_models/training_flooding/checkpoint/epoch=3-step=24271.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 30339: val_dice_loss was not in top True\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "falling-meter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of logits: torch.Size([32, 3, 256, 256])\n",
      "Shape of probs: torch.Size([32, 3, 256, 256])\n",
      "Shape of prediction: torch.Size([32, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Run inference on the images shown before\n",
    "\n",
    "logits = model(batch_train[\"image\"].to(model.device))\n",
    "print(f\"Shape of logits: {logits.shape}\")\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "print(f\"Shape of probs: {probs.shape}\")\n",
    "prediction = torch.argmax(probs, dim=1).long().cpu()\n",
    "print(f\"Shape of prediction: {prediction.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hearing-judges",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,3,256,256) (1,13,1,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-91ef00a1f6b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mflooding_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_images\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_clip_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3500.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m flooding_model.plot_batch(batch_train[\"image\"][:n_images],bands_show=[\"B11\",\"B8\", \"B4\"],\n\u001b[1;32m      5\u001b[0m                              axs=axs[1],max_clip_val=4500.)\n",
      "\u001b[0;32m~/viplab_projects/satellite-knowledge-distillation/models/flooding_model.py\u001b[0m in \u001b[0;36mplot_batch\u001b[0;34m(x, channel_configuration, bands_show, axs, max_clip_val, show_axis)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munnorm_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_configuration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_clip_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_clip_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m     \u001b[0mbands_read_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mBANDS_S2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCHANNELS_CONFIGURATIONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchannel_configuration\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0mbands_index_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbands_read_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbands_show\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/viplab_projects/satellite-knowledge-distillation/models/flooding_model.py\u001b[0m in \u001b[0;36munnorm_batch\u001b[0;34m(x, channel_configuration, max_clip_val)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# (1, nchannels, 1, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# (1, nchannels, 1, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_input_npy\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_clip_val\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmax_clip_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,3,256,256) (1,13,1,1) "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABQgAAAPoCAYAAACS9BPWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAABWnUlEQVR4nO3dXail910+/OtrxlSotYVmhJJJTYpT6+AjtN3EgqCFVkhykDlQJAGpldpBNCJYhEilSjwQFRTE+DJ/LdMWbJr2QEZMyfNHKwUxNbv0xSYhMsaXTCx0GvvkRGwM/J6DvdQ92z3dKzP3ernn+/lAYK+17uz9m7ku7oOLtWfVGCMAAAAAQE/ftOkDAAAAAACbYyAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjsyIGwqj5YVV+pqi9d4fWqqt+pqgtV9cWqesv0x2STdKA3+aMDvckfHehN/uhAb/JHB/pY5h2E55Lc8Q1evzPJycV/Z5L8/rUfiy1zLjrQ2bnIv7tz0YHOzkX+3Z2LDnR2LvLv7lx0oLNzkX9356IDLRw5EI4xPp3k377BJaeTfHjseSzJa6rqdVMdkM3Tgd7kjw70Jn90oDf5owO9yR8d6OPYBN/j5iTP7nt8cfHclw9eWFVnsrco55WvfOVb3/SmN03w4znos5/97FfHGMfX+CN1YMusuQPy3zLuAbgH9OYegHtAb+4BuAf05h7A1XZgioFwaWOMs0nOJsnOzs7Y3d1d549vo6r+edNnuBIdWI9t7YD812Nb8090YF22tQPyX49tzT/RgXXZ1g7Ifz22Nf9EB9ZlWzsg//XY1vwTHViXq+3AFJ9i/FySW/Y9PrF4jj50oDf5owO9yR8d6E3+6EBv8kcHrhNTDITnk7xr8ck1b0vywhjjf72VlOuaDvQmf3SgN/mjA73JHx3oTf7owHXiyF8xrqqPJnl7kpuq6mKSX07yzUkyxviDJI8kuSvJhST/nuQnVnVYNkMHepM/OtCb/NGB3uSPDvQmf3SgjyMHwjHGvUe8PpL8zGQnYuvoQG/yRwd6kz860Jv80YHe5I8O9DHFrxgDAAAAADNlIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQ2FIDYVXdUVVPV9WFqrr/kNdfX1WfqqrPVdUXq+qu6Y/KpsgfHUAHepM/OtCb/NGB3uSPDvRw5EBYVTckeTDJnUlOJbm3qk4duOyXkjw8xnhzknuS/N7UB2Uz5I8OoAO9yR8d6E3+6EBv8kcH+ljmHYS3J7kwxnhmjPFikoeSnD5wzUjybYuvX53kX6c7Ihsmf3QAHehN/uhAb/JHB3qTPzrQxDID4c1Jnt33+OLiuf1+JcmPVdXFJI8k+dnDvlFVnamq3aravXTp0lUclw2YLP9EB2bKPQAd6E3+6EBv8kcHepM/OtDEVB9Scm+Sc2OME0nuSvKRqvpf33uMcXaMsTPG2Dl+/PhEP5otsFT+iQ5cx9wD0IHe5I8O9CZ/dKA3+aMD14FlBsLnktyy7/GJxXP7vSfJw0kyxvibJN+S5KYpDsjGyR8dQAd6kz860Jv80YHe5I8ONLHMQPh4kpNVdVtV3Zi9f3Dy/IFr/iXJO5Kkqr47e2XwftHrg/zRAXSgN/mjA73JHx3oTf7oQBNHDoRjjJeS3Jfk0SRPZe+TaZ6oqgeq6u7FZe9L8t6q+kKSjyZ59xhjrOrQrI/80QF0oDf5owO9yR8d6E3+6EAfx5a5aIzxSPb+ocn9z31g39dPJvn+aY/GtpA/OoAO9CZ/dKA3+aMDvckfHehhqg8pAQAAAABmyEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNLTUQVtUdVfV0VV2oqvuvcM2PVtWTVfVEVf3JtMdkk+SPDvQmf3SgN/mjA73JHx1AB3o4dtQFVXVDkgeT/FCSi0ker6rzY4wn911zMskvJvn+McbXqurbV3Vg1kv+6EBv8kcHepM/OtCb/NEBdKCPZd5BeHuSC2OMZ8YYLyZ5KMnpA9e8N8mDY4yvJckY4yvTHpMNkj860Jv80YHe5I8O9CZ/dAAdaGKZgfDmJM/ue3xx8dx+b0zyxqr666p6rKruOOwbVdWZqtqtqt1Lly5d3YlZt8nyT3RgptwDenMPwD2gN/cA3AN6cw/APQAdaGKqDyk5luRkkrcnuTfJ/6mq1xy8aIxxdoyxM8bYOX78+EQ/mi2wVP6JDlzH3AN6cw/APaA39wDcA3pzD8A9AB24DiwzED6X5JZ9j08sntvvYpLzY4z/HGP8Y5K/z145mD/5owO9yR8d6E3+6EBv8kcH0IEmlhkIH09ysqpuq6obk9yT5PyBa/40e0txquqm7L299JnpjskGyR8d6E3+6EBv8kcHepM/OoAONHHkQDjGeCnJfUkeTfJUkofHGE9U1QNVdffiskeTPF9VTyb5VJJfGGM8v6pDsz7yRwd6kz860Jv80YHe5I8OoAN91BhjIz94Z2dn7O7ubuRnX++q6rNjjJ1Nn+MoOrA6c+iA/FdnDvknOrBKc+iA/FdnDvknOrBKc+iA/FdnDvknOrBKc+iA/FdnDvknOrBKV9uBqT6kBAAAAACYIQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMaWGgir6o6qerqqLlTV/d/guh+uqlFVO9MdkU2TPzqADvQmf3SgN/mjA73JHx3o4ciBsKpuSPJgkjuTnEpyb1WdOuS6VyX5uSSfmfqQbI780QF0oDf5owO9yR8d6E3+6EAfy7yD8PYkF8YYz4wxXkzyUJLTh1z3q0l+Pcl/THg+Nk/+6AA60Jv80YHe5I8O9CZ/dKCJZQbCm5M8u+/xxcVz/62q3pLkljHGn3+jb1RVZ6pqt6p2L1269LIPy0ZMlv/iWh2YH/cAdKA3+aMDvckfHehN/uhAE9f8ISVV9U1JfivJ+466doxxdoyxM8bYOX78+LX+aLbAy8k/0YHrkXsAOtCb/NGB3uSPDvQmf3Tg+rHMQPhcklv2PT6xeO6/vCrJ9yT5q6r6pyRvS3LeP0p53ZA/OoAO9CZ/dKA3+aMDvckfHWhimYHw8SQnq+q2qroxyT1Jzv/Xi2OMF8YYN40xbh1j3JrksSR3jzF2V3Ji1k3+6AA60Jv80YHe5I8O9CZ/dKCJIwfCMcZLSe5L8miSp5I8PMZ4oqoeqKq7V31ANkv+6AA60Jv80YHe5I8O9CZ/dKCPY8tcNMZ4JMkjB577wBWuffu1H4ttIn90AB3oTf7oQG/yRwd6kz860MM1f0gJAAAAADBfBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGhsqYGwqu6oqqer6kJV3X/I6z9fVU9W1Rer6i+q6jumPyqbIn90oDf5owO9yR8d6E3+6AA60MORA2FV3ZDkwSR3JjmV5N6qOnXgss8l2RljfG+STyT5jakPymbIHx3oTf7oQG/yRwd6kz86gA70scw7CG9PcmGM8cwY48UkDyU5vf+CMcanxhj/vnj4WJIT0x6TDZI/OtCb/NGB3uSPDvQmf3QAHWhimYHw5iTP7nt8cfHclbwnyScPe6GqzlTVblXtXrp0aflTskmT5Z/owEy5B/TmHoB7QG/uAbgH9OYegHsAOtDEpB9SUlU/lmQnyW8e9voY4+wYY2eMsXP8+PEpfzRb4Kj8Ex243rkH9OYegHtAb+4BuAf05h6AewA6MG/HlrjmuSS37Ht8YvHcZarqnUnen+QHxxhfn+Z4bAH5owO9yR8d6E3+6EBv8kcH0IEmlnkH4eNJTlbVbVV1Y5J7kpzff0FVvTnJHya5e4zxlemPyQbJHx3oTf7oQG/yRwd6kz86gA40ceRAOMZ4Kcl9SR5N8lSSh8cYT1TVA1V19+Ky30zyrUk+XlWfr6rzV/h2zIz80YHe5I8O9CZ/dKA3+aMD6EAfy/yKccYYjyR55MBzH9j39TsnPhdbRP7oQG/yRwd6kz860Jv80QF0oIdJP6QEAAAAAJgXAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxpYaCKvqjqp6uqouVNX9h7z+iqr62OL1z1TVrZOflI2RPzqADvQmf3SgN/mjA73JHx3o4ciBsKpuSPJgkjuTnEpyb1WdOnDZe5J8bYzxnUl+O8mvT31QNkP+6AA60Jv80YHe5I8O9CZ/dKCPZd5BeHuSC2OMZ8YYLyZ5KMnpA9ecTvKhxdefSPKOqqrpjskGyR8dQAd6kz860Jv80YHe5I8ONHFsiWtuTvLsvscXk3zfla4ZY7xUVS8keW2Sr+6/qKrOJDmzePj1qvrS1Rx6Q27KgT/PFvuuCb/XZPkns+7AnPJPtrQDM84/mVcHpsw/0YFkXvkn7gGrMKcOuAdMb075J+4BqzCnDrgHTG9O+SfuAaswpw64B0xvTvknV9mBZQbCyYwxziY5myRVtTvG2Fnnz78WczpvVe1u+gxXMtcOzOmsyfZ2YK75J/M677bmn8y3A3M6a7K9HZhr/sm8zrut+Sfz7cCczppsbwfmmn8yr/Nua/7JfDswp7Mm29uBueafzOu825p/Mt8OzOmsydV3YJlfMX4uyS37Hp9YPHfoNVV1LMmrkzx/NQdi68gfHUAHepM/OtCb/NGB3uSPDjSxzED4eJKTVXVbVd2Y5J4k5w9ccz7Jjy++/pEkfznGGNMdkw2SPzqADvQmf3SgN/mjA73JHx1o4shfMV78/vh9SR5NckOSD44xnqiqB5LsjjHOJ/njJB+pqgtJ/i17hTnK2Ws49ybM6byTnXWF+U96zjWY01mTeXSg7d/pGkx6Vh1IMq+zJu4BqzCn87oHTG9OZ03cA1ZhTud1D5jenM6auAeswpzO6x4wvTmdNbnK85ZRFwAAAAD6WuZXjAEAAACA65SBEAAAAAAaW/lAWFV3VNXTVXWhqu4/5PVXVNXHFq9/pqpuXfWZrmSJs767qi5V1ecX//3kJs65OMsHq+orVfWlK7xeVfU7iz/LF6vqLes+4+Ics8l/cR4dmNicOiD/6c0p/8V5dGBic+qA/Kc3p/wX59GBic2pA/Kf3pzyX5xHByY2pw7IfzV0YDVW0oExxsr+y94/YPkPSd6Q5MYkX0hy6sA1P53kDxZf35PkY6s80zWe9d1JfncT5zvkvD+Q5C1JvnSF1+9K8skkleRtST6zpX+nW5G/DuiA/HvnrwM6IP/e+euADsi/d/46oAPy1wEdGCt/B+HtSS6MMZ4ZY7yY5KEkpw9cczrJhxZffyLJO6qqVnyuwyxz1q0xxvh09j4d6EpOJ/nw2PNYktdU1evWc7r/Nqf8Ex1YhTl1QP7Tm1P+iQ6swpw6IP/pzSn/RAdWYU4dkP/05pR/ogOrMKcOyH81dGBFVtGBVQ+ENyd5dt/ji4vnDr1mjPFSkheSvHbF5zrMMmdNkh9evD3zE1V1y3qOdlWW/fNs+gzbkv9lZ1nQgfWcYVs6IP/NnGFb8r/sLAs6sJ4zbEsH5L+ZM2xL/pedZUEH1nOGbemA/Ddzhm3J/7KzLOjAes6wLR2Q/+bOoQOr8bI74ENKXp4/S3LrGON7k/zf/M/KTR860Jv80YHe5I8O9CZ/dKA3+XNdd2DVA+FzSfYvqicWzx16TVUdS/LqJM+v+FyHOfKsY4znxxhfXzz8oyRvXdPZrsYyf/fbcIZtyf+ysyzowHrOsC0dkP9mzrAt+V92lgUdWM8ZtqUD8t/MGbYl/8vOsqAD6znDtnRA/ps5w7bkf9lZFnRgPWfYlg7If3Pn0IHVeNkdWPVA+HiSk1V1W1XdmL1/cPL8gWvOJ/nxxdc/kuQvx9j7FxXX7MizHvh97buTPLXG871c55O8a/HJNW9L8sIY48trPsOc8k90YBXm1AH5T29O+Sc6sApz6oD8pzen/BMdWIU5dUD+05tT/okOrMKcOiD/1dCBzXn5HRir/2SVu5L8ffY+Deb9i+ceSHL34utvSfLxJBeS/G2SN6z6TNdw1l9L8kT2Ps3mU0netMGzfjTJl5P8Z/Z+l/w9SX4qyU8tXq8kDy7+LH+XZGdL/063Jn8d0AH5985fB3RA/r3z1wEdkH/v/HVAB+SvA907UIv/EQAAAABoyIeUAAAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjR05EFbVB6vqK1X1pSu8XlX1O1V1oaq+WFVvmf6YbJIO9CZ/dKA3+aMDvckfHehN/uhAH8u8g/Bckju+wet3Jjm5+O9Mkt+/9mOxZc5FBzo7F/l3dy460Nm5yL+7c9GBzs5F/t2diw50di7y7+5cdKCFIwfCMcank/zbN7jkdJIPjz2PJXlNVb1uqgOyeTrQm/zRgd7kjw70Jn90oDf5owN9TPFvEN6c5Nl9jy8unqMPHehN/uhAb/JHB3qTPzrQm/zRgevEsXX+sKo6k723nOaVr3zlW9/0pjet88e38dnPfvarY4zjmz7HYXRgPba1A/Jfj23NP9GBddnWDsh/PbY1/0QH1mVbOyD/9djW/BMdWJdt7YD812Nb8090YF2utgNTDITPJbll3+MTi+f+lzHG2SRnk2RnZ2fs7u5O8OM5qKr+ec0/Uge2zJo7IP8t4x6Ae0Bv7gG4B/TmHoB7QG/uAVxtB6b4FePzSd61+OSatyV5YYzx5Qm+L/OhA73JHx3oTf7oQG/yRwd6kz86cJ048h2EVfXRJG9PclNVXUzyy0m+OUnGGH+Q5JEkdyW5kOTfk/zEqg7LZuhAb/JHB3qTPzrQm/zRgd7kjw70ceRAOMa494jXR5KfmexEbB0d6E3+6EBv8kcHepM/OtCb/NGBPqb4FWMAAAAAYKYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaW2ogrKo7qurpqrpQVfcf8vrrq+pTVfW5qvpiVd01/VHZFPmjA+hAb/JHB3qTPzrQm/zRgR6OHAir6oYkDya5M8mpJPdW1akDl/1SkofHGG9Ock+S35v6oGyG/NEBdKA3+aMDvckfHehN/uhAH8u8g/D2JBfGGM+MMV5M8lCS0weuGUm+bfH1q5P863RHZMPkjw6gA73JHx3oTf7oQG/yRweaWGYgvDnJs/seX1w8t9+vJPmxqrqY5JEkP3vYN6qqM1W1W1W7ly5duorjsgGT5Z/owEy5B6ADvckfHehN/uhAb/JHB5qY6kNK7k1yboxxIsldST5SVf/re48xzo4xdsYYO8ePH5/oR7MFlso/0YHrmHsAOtCb/NGB3uSPDvQmf3TgOrDMQPhcklv2PT6xeG6/9yR5OEnGGH+T5FuS3DTFAdk4+aMD6EBv8kcHepM/OtCb/NGBJpYZCB9PcrKqbquqG7P3D06eP3DNvyR5R5JU1XdnrwzeL3p9kD86gA70Jn90oDf5owO9yR8daOLIgXCM8VKS+5I8muSp7H0yzRNV9UBV3b247H1J3ltVX0jy0STvHmOMVR2a9ZE/OoAO9CZ/dKA3+aMDvckfHejj2DIXjTEeyd4/NLn/uQ/s+/rJJN8/7dHYFvJHB9CB3uSPDvQmf3SgN/mjAz1M9SElAAAAAMAMGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKCxpQbCqrqjqp6uqgtVdf8VrvnRqnqyqp6oqj+Z9phskvzRgd7kjw70Jn90oDf5owPoQA/Hjrqgqm5I8mCSH0pyMcnjVXV+jPHkvmtOJvnFJN8/xvhaVX37qg7MeskfHehN/uhAb/JHB3qTPzqADvSxzDsIb09yYYzxzBjjxSQPJTl94Jr3JnlwjPG1JBljfGXaY7JB8kcHepM/OtCb/NGB3uSPDqADTSwzEN6c5Nl9jy8untvvjUneWFV/XVWPVdUdUx2QjZM/OtCb/NGB3uSPDvQmf3QAHWjiyF8xfhnf52SStyc5keTTVfX/jDH+v/0XVdWZJGeS5PWvf/1EP5otsFT+iQ5cx9wDenMPwD2gN/cA3AN6cw/APQAduA4s8w7C55Lcsu/xicVz+11Mcn6M8Z9jjH9M8vfZK8dlxhhnxxg7Y4yd48ePX+2ZWa/J8k90YKbcA3pzD8A9oDf3ANwDenMPwD0AHWhimYHw8SQnq+q2qroxyT1Jzh+45k+ztxSnqm7K3ttLn5numGyQ/NGB3uSPDvQmf3SgN/mjA+hAE0cOhGOMl5Lcl+TRJE8leXiM8URVPVBVdy8uezTJ81X1ZJJPJfmFMcbzqzo06yN/dKA3+aMDvckfHehN/ugAOtBHjTE28oN3dnbG7u7uRn729a6qPjvG2Nn0OY6iA6szhw7If3XmkH+iA6s0hw7If3XmkH+iA6s0hw7If3XmkH+iA6s0hw7If3XmkH+iA6t0tR1Y5leMAQAAAIDrlIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGNLDYRVdUdVPV1VF6rq/m9w3Q9X1aiqnemOyKbJHx1AB3qTPzrQm/zRgd7kjw70cORAWFU3JHkwyZ1JTiW5t6pOHXLdq5L8XJLPTH1INkf+6AA60Jv80YHe5I8O9CZ/dKCPZd5BeHuSC2OMZ8YYLyZ5KMnpQ6771SS/nuQ/Jjwfmyd/dAAd6E3+6EBv8kcHepM/OtDEMgPhzUme3ff44uK5/1ZVb0lyyxjjz7/RN6qqM1W1W1W7ly5detmHZSMmy39xrQ7Mj3sAOtCb/NGB3uSPDvQmf3SgiWv+kJKq+qYkv5XkfUddO8Y4O8bYGWPsHD9+/Fp/NFvg5eSf6MD1yD0AHehN/uhAb/JHB3qTPzpw/VhmIHwuyS37Hp9YPPdfXpXke5L8VVX9U5K3JTnvH6W8bsgfHUAHepM/OtCb/NGB3uSPDjSxzED4eJKTVXVbVd2Y5J4k5//rxTHGC2OMm8YYt44xbk3yWJK7xxi7Kzkx6yZ/dAAd6E3+6EBv8kcHepM/OtDEkQPhGOOlJPcleTTJU0keHmM8UVUPVNXdqz4gmyV/dAAd6E3+6EBv8kcHepM/OtDHsWUuGmM8kuSRA8994ArXvv3aj8U2kT86gA70Jn90oDf5owO9yR8d6OGaP6QEAAAAAJgvAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADS21EBYVXdU1dNVdaGq7j/k9Z+vqier6otV9RdV9R3TH5VNkT860Jv80YHe5I8O9CZ/dAAd6OHIgbCqbkjyYJI7k5xKcm9VnTpw2eeS7IwxvjfJJ5L8xtQHZTPkjw70Jn90oDf5owO9yR8dQAf6WOYdhLcnuTDGeGaM8WKSh5Kc3n/BGONTY4x/Xzx8LMmJaY/JBskfHehN/uhAb/JHB3qTPzqADjSxzEB4c5Jn9z2+uHjuSt6T5JPXcii2ivzRgd7kjw70Jn90oDf5owPoQBPHpvxmVfVjSXaS/OAVXj+T5EySvP71r5/yR7MFjsp/cY0OXMfcA3pzD8A9oDf3ANwDenMPwD0AHZi3Zd5B+FySW/Y9PrF47jJV9c4k709y9xjj64d9ozHG2THGzhhj5/jx41dzXtZvsvwTHZgp94De3ANwD+jNPQD3gN7cA3APQAeaWGYgfDzJyaq6rapuTHJPkvP7L6iqNyf5w+wV4SvTH5MNkj860Jv80YHe5I8O9CZ/dAAdaOLIgXCM8VKS+5I8muSpJA+PMZ6oqgeq6u7FZb+Z5FuTfLyqPl9V56/w7ZgZ+aMDvckfHehN/uhAb/JHB9CBPpb6NwjHGI8keeTAcx/Y9/U7Jz4XW0T+6EBv8kcHepM/OtCb/NEBdKCHZX7FGAAAAAC4ThkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADS21EBYVXdU1dNVdaGq7j/k9VdU1ccWr3+mqm6d/KRsjPzRAXSgN/mjA73JHx3oTf7oQA9HDoRVdUOSB5PcmeRUknur6tSBy96T5GtjjO9M8ttJfn3qg7IZ8kcH0IHe5I8O9CZ/dKA3+aMDfSzzDsLbk1wYYzwzxngxyUNJTh+45nSSDy2+/kSSd1RVTXdMNkj+6AA60Jv80YHe5I8O9CZ/dKCJY0tcc3OSZ/c9vpjk+650zRjjpap6Iclrk3x1/0VVdSbJmcXDr1fVl67m0BtyUw78ebbYd034vSbLP5l1B+aUf7KlHZhx/sm8OjBl/okOJPPKP3EPWIU5dcA9YHpzyj9xD1iFOXXAPWB6c8o/cQ9YhTl1wD1genPKP7nKDiwzEE5mjHE2ydkkqardMcbOOn/+tZjTeatqd9NnuJK5dmBOZ022twNzzT+Z13m3Nf9kvh2Y01mT7e3AXPNP5nXebc0/mW8H5nTWZHs7MNf8k3mdd1vzT+bbgTmdNdneDsw1/2Re593W/JP5dmBOZ02uvgPL/Irxc0lu2ff4xOK5Q6+pqmNJXp3k+as5EFtH/ugAOtCb/NGB3uSPDvQmf3SgiWUGwseTnKyq26rqxiT3JDl/4JrzSX588fWPJPnLMcaY7phskPzRAXSgN/mjA73JHx3oTf7oQBNH/orx4vfH70vyaJIbknxwjPFEVT2QZHeMcT7JHyf5SFVdSPJv2SvMUc5ew7k3YU7nneysK8x/0nOuwZzOmsyjA23/Ttdg0rPqQJJ5nTVxD1iFOZ3XPWB6czpr4h6wCnM6r3vA9OZ01sQ9YBXmdF73gOnN6azJVZ63jLoAAAAA0Ncyv2IMAAAAAFynDIQAAAAA0NjKB8KquqOqnq6qC1V1/yGvv6KqPrZ4/TNVdeuqz3QlS5z13VV1qao+v/jvJzdxzsVZPlhVX6mqL13h9aqq31n8Wb5YVW9Z9xkX55hN/ovz6MDE5tQB+U9vTvkvzqMDE5tTB+Q/vTnlvziPDkxsTh2Q//TmlP/iPDowsTl1QP6roQOrsZIOjDFW9l/2/gHLf0jyhiQ3JvlCklMHrvnpJH+w+PqeJB9b5Zmu8azvTvK7mzjfIef9gSRvSfKlK7x+V5JPJqkkb0vymS39O92K/HVAB+TfO38d0AH5985fB3RA/r3z1wEdkL8O6MBY+TsIb09yYYzxzBjjxSQPJTl94JrTST60+PoTSd5RVbXicx1mmbNujTHGp7P36UBXcjrJh8eex5K8pqpet57T/bc55Z/owCrMqQPyn96c8k90YBXm1AH5T29O+Sc6sApz6oD8pzen/BMdWIU5dUD+q6EDK7KKDqx6ILw5ybP7Hl9cPHfoNWOMl5K8kOS1Kz7XYZY5a5L88OLtmZ+oqlvWc7SrsuyfZ9Nn2Jb8LzvLgg6s5wzb0gH5b+YM25L/ZWdZ0IH1nGFbOiD/zZxhW/K/7CwLOrCeM2xLB+S/mTNsS/6XnWVBB9Zzhm3pgPw3dw4dWI2X3QEfUvLy/FmSW8cY35vk/+Z/Vm760IHe5I8O9CZ/dKA3+aMDvcmf67oDqx4In0uyf1E9sXju0Guq6liSVyd5fsXnOsyRZx1jPD/G+Pri4R8leeuaznY1lvm734YzbEv+l51lQQfWc4Zt6YD8N3OGbcn/srMs6MB6zrAtHZD/Zs6wLflfdpYFHVjPGbalA/LfzBm2Jf/LzrKgA+s5w7Z0QP6bO4cOrMbL7sCqB8LHk5ysqtuq6sbs/YOT5w9ccz7Jjy++/pEkfznG3r+ouGZHnvXA72vfneSpNZ7v5Tqf5F2LT655W5IXxhhfXvMZ5pR/ogOrMKcOyH96c8o/0YFVmFMH5D+9OeWf6MAqzKkD8p/enPJPdGAV5tQB+a+GDmzOy+/AWP0nq9yV5O+z92kw718890CSuxdff0uSjye5kORvk7xh1We6hrP+WpInsvdpNp9K8qYNnvWjSb6c5D+z97vk70nyU0l+avF6JXlw8Wf5uyQ7W/p3ujX564AOyL93/jqgA/Lvnb8O6ID8e+evAzogfx3o3oFa/I8AAAAAQEM+pAQAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjR05EFbVB6vqK1X1pSu8XlX1O1V1oaq+WFVvmf6YbJIO9CZ/dKA3+aMDvckfHehN/uhAH8u8g/Bckju+wet3Jjm5+O9Mkt+/9mOxZc5FBzo7F/l3dy460Nm5yL+7c9GBzs5F/t2diw50di7y7+5cdKCFIwfCMcank/zbN7jkdJIPjz2PJXlNVb1uqgOyeTrQm/zRgd7kjw70Jn90oDf5owN9HJvge9yc5Nl9jy8unvvywQur6kz2FuW88pWvfOub3vSmCX48B332s5/96hjj+Bp/pA5smTV3QP5bxj0A94De3ANwD+jNPQD3gN7cA7jaDkwxEC5tjHE2ydkk2dnZGbu7u+v88W1U1T9v+gxXogPrsa0dkP96bGv+iQ6sy7Z2QP7rsa35JzqwLtvaAfmvx7bmn+jAumxrB+S/Htuaf6ID63K1HZjiU4yfS3LLvscnFs/Rhw70Jn90oDf5owO9yR8d6E3+6MB1YoqB8HySdy0+ueZtSV4YY/yvt5JyXdOB3uSPDvQmf3SgN/mjA73JHx24Thz5K8ZV9dEkb09yU1VdTPLLSb45ScYYf5DkkSR3JbmQ5N+T/MSqDstm6EBv8kcHepM/OtCb/NGB3uSPDvRx5EA4xrj3iNdHkp+Z7ERsHR3oTf7oQG/yRwd6kz860Jv80YE+pvgVYwAAAABgpgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQ2FIDYVXdUVVPV9WFqrr/kNdfX1WfqqrPVdUXq+qu6Y/KpsgfHUAHepM/OtCb/NGB3uSPDvRw5EBYVTckeTDJnUlOJbm3qk4duOyXkjw8xnhzknuS/N7UB2Uz5I8OoAO9yR8d6E3+6EBv8kcH+ljmHYS3J7kwxnhmjPFikoeSnD5wzUjybYuvX53kX6c7Ihsmf3QAHehN/uhAb/JHB3qTPzrQxLElrrk5ybP7Hl9M8n0HrvmVJP9vVf1sklcmeeckp2MbyB8dQAd6kz860Jv80YHe5I8ONDHVh5Tcm+TcGONEkruSfKSq/tf3rqozVbVbVbuXLl2a6EezBZbKP9GB65h7ADrQm/zRgd7kjw70Jn904DqwzED4XJJb9j0+sXhuv/ckeThJxhh/k+Rbktx08BuNMc6OMXbGGDvHjx+/uhOzbpPlv3hdB+bHPQAd6E3+6EBv8kcHepM/OtDEMgPh40lOVtVtVXVj9v7ByfMHrvmXJO9Ikqr67uyVwRx8fZA/OoAO9CZ/dKA3+aMDvckfHWjiyIFwjPFSkvuSPJrkqex9Ms0TVfVAVd29uOx9Sd5bVV9I8tEk7x5jjFUdmvWRPzqADvQmf3SgN/mjA73JHx3oY5kPKckY45Ekjxx47gP7vn4yyfdPezS2hfzRAXSgN/mjA73JHx3oTf7oQA9TfUgJAAAAADBDBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjS01EFbVHVX1dFVdqKr7r3DNj1bVk1X1RFX9ybTHZJPkjw70Jn90oDf5owO9yR8dQAd6OHbUBVV1Q5IHk/xQkotJHq+q82OMJ/ddczLJLyb5/jHG16rq21d1YNZL/uhAb/JHB3qTPzrQm/zRAXSgj2XeQXh7kgtjjGfGGC8meSjJ6QPXvDfJg2OMryXJGOMr0x6TDZI/OtCb/NGB3uSPDvQmf3QAHWhimYHw5iTP7nt8cfHcfm9M8saq+uuqeqyq7jjsG1XVmararardS5cuXd2JWbfJ8k90YKbcA3pzD8A9oDf3ANwDenMPwD0AHWhiqg8pOZbkZJK3J7k3yf+pqtccvGiMcXaMsTPG2Dl+/PhEP5otsFT+iQ5cx9wDenMPwD2gN/cA3AN6cw/APQAduA4sMxA+l+SWfY9PLJ7b72KS82OM/xxj/GOSv89eOZg/+aMDvckfHehN/uhAb/JHB9CBJpYZCB9PcrKqbquqG5Pck+T8gWv+NHtLcarqpuy9vfSZ6Y7JBskfHehN/uhAb/JHB3qTPzqADjRx5EA4xngpyX1JHk3yVJKHxxhPVNUDVXX34rJHkzxfVU8m+VSSXxhjPL+qQ7M+8kcHepM/OtCb/NGB3uSPDqADfdQYYyM/eGdnZ+zu7m7kZ1/vquqzY4ydTZ/jKDqwOnPogPxXZw75JzqwSnPogPxXZw75JzqwSnPogPxXZw75JzqwSnPogPxXZw75JzqwSlfbgak+pAQAAAAAmCEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKAxAyEAAAAANLbUQFhVd1TV01V1oaru/wbX/XBVjarame6IbJr80QF0oDf5owO9yR8d6E3+6EAPRw6EVXVDkgeT3JnkVJJ7q+rUIde9KsnPJfnM1Idkc+SPDqADvckfHehN/uhAb/JHB/pY5h2Etye5MMZ4ZozxYpKHkpw+5LpfTfLrSf5jwvOxefJHB9CB3uSPDvQmf3SgN/mjA00sMxDenOTZfY8vLp77b1X1liS3jDH+fMKzsR3kjw6gA73JHx3oTf7oQG/yRweauOYPKamqb0ryW0net8S1Z6pqt6p2L126dK0/mi3wcvJfXK8D1xn3AHSgN/mjA73JHx3oTf7owPVjmYHwuSS37Ht8YvHcf3lVku9J8ldV9U9J3pbk/GH/KOUY4+wYY2eMsXP8+PGrPzXrNFn+iQ7MlHsAOtCb/NGB3uSPDvQmf3SgiWUGwseTnKyq26rqxiT3JDn/Xy+OMV4YY9w0xrh1jHFrkseS3D3G2F3JiVk3+aMD6EBv8kcHepM/OtCb/NGBJo4cCMcYLyW5L8mjSZ5K8vAY44mqeqCq7l71Adks+aMD6EBv8kcHepM/OtCb/NGBPo4tc9EY45Ekjxx47gNXuPbt134ston80QF0oDf5owO9yR8d6E3+6EAP1/whJQAAAADAfBkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADS21EBYVXdU1dNVdaGq7j/k9Z+vqier6otV9RdV9R3TH5VNkT860Jv80YHe5I8O9CZ/dAAd6OHIgbCqbkjyYJI7k5xKcm9VnTpw2eeS7IwxvjfJJ5L8xtQHZTPkjw70Jn90oDf5owO9yR8dQAf6WOYdhLcnuTDGeGaM8WKSh5Kc3n/BGONTY4x/Xzx8LMmJaY/JBskfHehN/uhAb/JHB3qTPzqADjSxzEB4c5Jn9z2+uHjuSt6T5JOHvVBVZ6pqt6p2L126tPwp2aTJ8k90YKbcA3pzD8A9oDf3ANwDenMPwD0AHWhi0g8pqaofS7KT5DcPe32McXaMsTPG2Dl+/PiUP5otcFT+iQ5c79wDenMPwD2gN/cA3AN6cw/APQAdmLdjS1zzXJJb9j0+sXjuMlX1ziTvT/KDY4yvT3M8toD80YHe5I8O9CZ/dKA3+aMD6EATy7yD8PEkJ6vqtqq6Mck9Sc7vv6Cq3pzkD5PcPcb4yvTHZIPkjw70Jn90oDf5owO9yR8dQAeaOHIgHGO8lOS+JI8meSrJw2OMJ6rqgaq6e3HZbyb51iQfr6rPV9X5K3w7Zkb+6EBv8kcHepM/OtCb/NEBdKCPZX7FOGOMR5I8cuC5D+z7+p0Tn4stIn90oDf5owO9yR8d6E3+6AA60MOkH1ICAAAAAMyLgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABpbaiCsqjuq6umqulBV9x/y+iuq6mOL1z9TVbdOflI2Rv7oADrQm/zRgd7kjw70Jn90oIcjB8KquiHJg0nuTHIqyb1VderAZe9J8rUxxncm+e0kvz71QdkM+aMD6EBv8kcHepM/OtCb/NGBPpZ5B+HtSS6MMZ4ZY7yY5KEkpw9cczrJhxZffyLJO6qqpjsmGyR/dAAd6E3+6EBv8kcHepM/OtDEMgPhzUme3ff44uK5Q68ZY7yU5IUkr53igGyc/NEBdKA3+aMDvckfHehN/uhAE8fW+cOq6kySM4uHX6+qL63z51+jm5J8ddOHWNJ3bfoAVzLjDswp/2RLOzDj/JN5dWAr809m3YE55Z9saQdmnH8yrw5sZf7JrDswp/yTLe3AjPNP5tWBrcw/mXUH5pR/sqUdmHH+ybw6sJX5J7PuwJzyT66yA8sMhM8luWXf4xOL5w675mJVHUvy6iTPH/xGY4yzSc4mSVXtjjF2rubQmzCn81bV7oTfbrL8k/l2YE5nTba3A3PNP5nXeSfOP9GBWZ01cQ9YhTmd1z1genM6a+IesApzOq97wPTmdNbEPWAV5nRe94DpzemsydV3YJlfMX48ycmquq2qbkxyT5LzB645n+THF1//SJK/HGOMqzkQW0f+6AA60Jv80YHe5I8O9CZ/dKCJI99BOMZ4qaruS/JokhuSfHCM8URVPZBkd4xxPskfJ/lIVV1I8m/ZKwzXAfmjA+hAb/JHB3qTPzrQm/zRgT5qU6NuVZ1ZvL10FuZ03rmcdS7nTOZ11mQe553DGfeb03nncta5nDOZ11mTeZx3Dmfcb07nnctZ53LOZF5nTeZx3jmccb85nXcuZ53LOZN5nTWZx3nncMb95nTeuZx1LudM5nXW5OrPu7GBEAAAAADYvGX+DUIAAAAA4Dq18oGwqu6oqqer6kJV3X/I66+oqo8tXv9MVd266jNdyRJnfXdVXaqqzy/++8lNnHNxlg9W1VfqCh8LXnt+Z/Fn+WJVvWXdZ1ycYzb5L86jAxObUwfkP7055b84jw5MbE4dkP/05pT/4jw6MLE5dUD+05tT/ovz6MDE5tQB+a+GDqzGSjowxljZf9n7Byz/IckbktyY5AtJTh245qeT/MHi63uSfGyVZ7rGs747ye9u4nyHnPcHkrwlyZeu8PpdST6ZpJK8LclntvTvdCvy1wEdkH/v/HVAB+TfO38d0AH5985fB3RA/jqgA2Pl7yC8PcmFMcYzY4wXkzyU5PSBa04n+dDi608keUdV1YrPdZhlzro1xhifzt6nA13J6SQfHnseS/Kaqnrdek733+aUf6IDqzCnDsh/enPKP9GBVZhTB+Q/vTnln+jAKsypA/Kf3pzyT3RgFebUAfmvhg6syCo6sOqB8OYkz+57fHHx3KHXjDFeSvJCkteu+FyHWeasSfLDi7dnfqKqblnP0a7Ksn+eTZ9hW/K/7CwLOrCeM2xLB+S/mTNsS/6XnWVBB9Zzhm3pgPw3c4Ztyf+ysyzowHrOsC0dkP9mzrAt+V92lgUdWM8ZtqUD8t/cOXRgNV52B3xIycvzZ0luHWN8b5L/m/9ZuelDB3qTPzrQm/zRgd7kjw70Jn+u6w6seiB8Lsn+RfXE4rlDr6mqY0leneT5FZ/rMEeedYzx/Bjj64uHf5TkrWs629VY5u9+G86wLflfdpYFHVjPGbalA/LfzBm2Jf/LzrKgA+s5w7Z0QP6bOcO25H/ZWRZ0YD1n2JYOyH8zZ9iW/C87y4IOrOcM29IB+W/uHDqwGi+7A6seCB9PcrKqbquqG7P3D06eP3DN+SQ/vvj6R5L85Rh7/6Limh151gO/r313kqfWeL6X63ySdy0+ueZtSV4YY3x5zWeYU/6JDqzCnDog/+nNKf9EB1ZhTh2Q//TmlH+iA6swpw7If3pzyj/RgVWYUwfkvxo6sDkvvwNj9Z+scleSv8/ep8G8f/HcA0nuXnz9LUk+nuRCkr9N8oZVn+kazvprSZ7I3qfZfCrJmzZ41o8m+XKS/8ze75K/J8lPJfmpxeuV5MHFn+Xvkuxs6d/p1uSvAzog/97564AOyL93/jqgA/Lvnb8O6ID8daB7B2rxPwIAAAAADfmQEgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0duRAWFUfrKqvVNWXrvB6VdXvVNWFqvpiVb1l+mOySTrQm/zRgd7kjw70Jn90oDf5owN9LPMOwnNJ7vgGr9+Z5OTivzNJfv/aj8WWORcd6Oxc5N/duehAZ+ci/+7ORQc6Oxf5d3cuOtDZuci/u3PRgRaOHAjHGJ9O8m/f4JLTST489jyW5DVV9bqpDsjm6UBv8kcHepM/OtCb/NGB3uSPDvRxbILvcXOSZ/c9vrh47ssHL6yqM9lblPPKV77yrW9605sm+PEc9NnPfvarY4zja/yROrBl1twB+W8Z9wDcA3pzD8A9oDf3ANwDenMP4Go7MMVAuLQxxtkkZ5NkZ2dn7O7urvPHt1FV/7zpM1yJDqzHtnZA/uuxrfknOrAu29oB+a/Htuaf6MC6bGsH5L8e25p/ogPrsq0dkP96bGv+iQ6sy9V2YIpPMX4uyS37Hp9YPEcfOtCb/NGB3uSPDvQmf3SgN/mjA9eJKQbC80netfjkmrcleWGM8b/eSsp1TQd6kz860Jv80YHe5I8O9CZ/dOA6ceSvGFfVR5O8PclNVXUxyS8n+eYkGWP8QZJHktyV5EKSf0/yE6s6LJuhA73JHx3oTf7oQG/yRwd6kz860MeRA+EY494jXh9JfmayE7F1dKA3+aMDvckfHehN/uhAb/JHB/qY4leMAQAAAICZMhACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaGypgbCq7qiqp6vqQlXdf8jrr6+qT1XV56rqi1V11/RHZVPkjw6gA73JHx3oTf7oQG/yRwd6OHIgrKobkjyY5M4kp5LcW1WnDlz2S0keHmO8Ock9SX5v6oOyGfJHB9CB3uSPDvQmf3SgN/mjA30s8w7C25NcGGM8M8Z4MclDSU4fuGYk+bbF169O8q/THZENkz86gA70Jn90oDf5owO9yR8daGKZgfDmJM/ue3xx8dx+v5Lkx6rqYpJHkvzsYd+oqs5U1W5V7V66dOkqjssGTJZ/ogMz5R6ADvQmf3SgN/mjA73JHx1oYqoPKbk3ybkxxokkdyX5SFX9r+89xjg7xtgZY+wcP358oh/NFlgq/0QHrmPuAehAb/JHB3qTPzrQm/zRgevAMgPhc0lu2ff4xOK5/d6T5OEkGWP8TZJvSXLTFAdk4+SPDqADvckfHehN/uhAb/JHB5pYZiB8PMnJqrqtqm7M3j84ef7ANf+S5B1JUlXfnb0yeL/o9UH+6AA60Jv80YHe5I8O9CZ/dKCJIwfCMcZLSe5L8miSp7L3yTRPVNUDVXX34rL3JXlvVX0hyUeTvHuMMVZ1aNZH/ugAOtCb/NGB3uSPDvQmf3Sgj2PLXDTGeCR7/9Dk/uc+sO/rJ5N8/7RHY1vIHx1AB3qTPzrQm/zRgd7kjw70MNWHlAAAAAAAM2QgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxpYaCKvqjqp6uqouVNX9V7jmR6vqyap6oqr+ZNpjsknyRwd6kz860Jv80YHe5I8OoAM9HDvqgqq6IcmDSX4oycUkj1fV+THGk/uuOZnkF5N8/xjja1X17as6MOslf3SgN/mjA73JHx3oTf7oADrQxzLvILw9yYUxxjNjjBeTPJTk9IFr3pvkwTHG15JkjPGVaY/JBskfHehN/uhAb/JHB3qTPzqADjSxzEB4c5Jn9z2+uHhuvzcmeWNV/XVVPVZVdxz2jarqTFXtVtXupUuXru7ErNtk+Sc6MFPuAb25B+Ae0Jt7AO4BvbkH4B6ADjQx1YeUHEtyMsnbk9yb5P9U1WsOXjTGODvG2Blj7Bw/fnyiH80WWCr/RAeuY+4BvbkH4B7Qm3sA7gG9uQfgHoAOXAeWGQifS3LLvscnFs/tdzHJ+THGf44x/jHJ32evHMyf/NGB3uSPDvQmf3SgN/mjA+hAE8sMhI8nOVlVt1XVjUnuSXL+wDV/mr2lOFV1U/beXvrMdMdkg+SPDvQmf3SgN/mjA73JHx1AB5o4ciAcY7yU5L4kjyZ5KsnDY4wnquqBqrp7cdmjSZ6vqieTfCrJL4wxnl/VoVkf+aMDvckfHehN/uhAb/JHB9CBPmqMsZEfvLOzM3Z3dzfys693VfXZMcbOps9xFB1YnTl0QP6rM4f8Ex1YpTl0QP6rM4f8Ex1YpTl0QP6rM4f8Ex1YpTl0QP6rM4f8Ex1YpavtwFQfUgIAAAAAzJCBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjSw2EVXVHVT1dVReq6v5vcN0PV9Woqp3pjsimyR8dQAd6kz860Jv80YHe5I8O9HDkQFhVNyR5MMmdSU4lubeqTh1y3auS/FySz0x9SDZH/ugAOtCb/NGB3uSPDvQmf3Sgj2XeQXh7kgtjjGfGGC8meSjJ6UOu+9Ukv57kPyY8H5snf3QAHehN/uhAb/JHB3qTPzrQxDID4c1Jnt33+OLiuf9WVW9JcssY48+/0TeqqjNVtVtVu5cuXXrZh2UjJst/ca0OzI97ADrQm/zRgd7kjw70Jn90oIlr/pCSqvqmJL+V5H1HXTvGODvG2Blj7Bw/fvxafzRb4OXkn+jA9cg9AB3oTf7oQG/yRwd6kz86cP1YZiB8Lskt+x6fWDz3X16V5HuS/FVV/VOStyU57x+lvG7IHx1AB3qTPzrQm/zRgd7kjw40scxA+HiSk1V1W1XdmOSeJOf/68UxxgtjjJvGGLeOMW5N8liSu8cYuys5Mesmf3QAHehN/uhAb/JHB3qTPzrQxJED4RjjpST3JXk0yVNJHh5jPFFVD1TV3as+IJslf3QAHehN/uhAb/JHB3qTPzrQx7FlLhpjPJLkkQPPfeAK17792o/FNpE/OoAO9CZ/dKA3+aMDvckfHejhmj+kBAAAAACYLwMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ttRAWFV3VNXTVXWhqu4/5PWfr6onq+qLVfUXVfUd0x+VTZE/OtCb/NGB3uSPDvQmf3QAHejhyIGwqm5I8mCSO5OcSnJvVZ06cNnnkuyMMb43ySeS/MbUB2Uz5I8O9CZ/dKA3+aMDvckfHUAH+ljmHYS3J7kwxnhmjPFikoeSnN5/wRjjU2OMf188fCzJiWmPyQbJHx3oTf7oQG/yRwd6kz86gA40scxAeHOSZ/c9vrh47krek+STh71QVWeqareqdi9durT8KdmkyfJPdGCm3AN6cw/APaA39wDcA3pzD8A9AB1oYtIPKamqH0uyk+Q3D3t9jHF2jLEzxtg5fvz4lD+aLXBU/okOXO/cA3pzD8A9oDf3ANwDenMPwD0AHZi3Y0tc81ySW/Y9PrF47jJV9c4k70/yg2OMr09zPLaA/NGB3uSPDvQmf3SgN/mjA+hAE8u8g/DxJCer6raqujHJPUnO77+gqt6c5A+T3D3G+Mr0x2SD5I8O9CZ/dKA3+aMDvckfHUAHmjhyIBxjvJTkviSPJnkqycNjjCeq6oGquntx2W8m+dYkH6+qz1fV+St8O2ZG/uhAb/JHB3qTPzrQm/zRAXSgj2V+xThjjEeSPHLguQ/s+/qdE5+LLSJ/dKA3+aMDvckfHehN/ugAOtDDpB9SAgAAAADMi4EQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGMGQgAAAABozEAIAAAAAI0ZCAEAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaMxACAAAAACNGQgBAAAAoDEDIQAAAAA0ZiAEAAAAgMYMhAAAAADQmIEQAAAAABozEAIAAABAYwZCAAAAAGjMQAgAAAAAjRkIAQAAAKAxAyEAAAAANGYgBAAAAIDGDIQAAAAA0JiBEAAAAAAaMxACAAAAQGNLDYRVdUdVPV1VF6rq/kNef0VVfWzx+meq6tbJT8rGyB8dQAd6kz860Jv80YHe5I8O9HDkQFhVNyR5MMmdSU4lubeqTh247D1JvjbG+M4kv53k16c+KJshf3QAHehN/uhAb/JHB3qTPzrQxzLvILw9yYUxxjNjjBeTPJTk9IFrTif50OLrTyR5R1XVdMdkg+SPDqADvckfHehN/uhAb/JHB5o4tsQ1Nyd5dt/ji0m+70rXjDFeqqoXkrw2yVf3X1RVZ5KcWTz8elV96WoOvSE35cCfZ4t914Tfa7L8k1l3YE75J1vagRnnn8yrA1Pmn+hAMq/8E/eAVZhTB9wDpjen/BP3gFWYUwfcA6Y3p/wT94BVmFMH3AOmN6f8k6vswDID4WTGGGeTnE2SqtodY+ys8+dfizmdt6p2N32GK5lrB+Z01mR7OzDX/JN5nXdb80/m24E5nTXZ3g7MNf9kXufd1vyT+XZgTmdNtrcDc80/mdd5tzX/ZL4dmNNZk+3twFzzT+Z13m3NP5lvB+Z01uTqO7DMrxg/l+SWfY9PLJ479JqqOpbk1Umev5oDsXXkjw6gA73JHx3oTf7oQG/yRweaWGYgfDzJyaq6rapuTHJPkvMHrjmf5McXX/9Ikr8cY4zpjskGyR8dQAd6kz860Jv80YHe5I8ONHHkrxgvfn/8viSPJrkhyQfHGE9U1QNJdscY55P8cZKPVNWFJP+WvcIc5ew1nHsT5nTeyc66wvwnPecazOmsyTw60PbvdA0mPasOJJnXWRP3gFWY03ndA6Y3p7Mm7gGrMKfzugdMb05nTdwDVmFO53UPmN6czppc5XnLqAsAAAAAfS3zK8YAAAAAwHXKQAgAAAAAja18IKyqO6rq6aq6UFX3H/L6K6rqY4vXP1NVt676TFeyxFnfXVWXqurzi/9+chPnXJzlg1X1lar60hVer6r6ncWf5YtV9ZZ1n3FxjtnkvziPDkxsTh2Q//TmlP/iPDowsTl1QP7Tm1P+i/PowMTm1AH5T29O+S/OowMTm1MH5L8aOrAaK+nAGGNl/2XvH7D8hyRvSHJjki8kOXXgmp9O8geLr+9J8rFVnukaz/ruJL+7ifMdct4fSPKWJF+6wut3JflkkkrytiSf2dK/063IXwd0QP6989cBHZB/7/x1QAfk3zt/HdAB+euADoyVv4Pw9iQXxhjPjDFeTPJQktMHrjmd5EOLrz+R5B1VVSs+12GWOevWGGN8OnufDnQlp5N8eOx5LMlrqup16zndf5tT/okOrMKcOiD/6c0p/0QHVmFOHZD/9OaUf6IDqzCnDsh/enPKP9GBVZhTB+S/GjqwIqvowKoHwpuTPLvv8cXFc4deM8Z4KckLSV674nMdZpmzJskPL96e+YmqumU9R7sqy/55Nn2Gbcn/srMs6MB6zrAtHZD/Zs6wLflfdpYFHVjPGbalA/LfzBm2Jf/LzrKgA+s5w7Z0QP6bOcO25H/ZWRZ0YD1n2JYOyH9z59CB1XjZHfAhJS/PnyW5dYzxvUn+b/5n5aYPHehN/uhAb/JHB3qTPzrQm/y5rjuw6oHwuST7F9UTi+cOvaaqjiV5dZLnV3yuwxx51jHG82OMry8e/lGSt67pbFdjmb/7bTjDtuR/2VkWdGA9Z9iWDsh/M2fYlvwvO8uCDqznDNvSAflv5gzbkv9lZ1nQgfWcYVs6IP/NnGFb8r/sLAs6sJ4zbEsH5L+5c+jAarzsDqx6IHw8ycmquq2qbszePzh5/sA155P8+OLrH0nyl2Ps/YuKa3bkWQ/8vvbdSZ5a4/lervNJ3rX45Jq3JXlhjPHlNZ9hTvknOrAKc+qA/Kc3p/wTHViFOXVA/tObU/6JDqzCnDog/+nNKf9EB1ZhTh2Q/2rowOa8/A6M1X+yyl1J/j57nwbz/sVzDyS5e/H1tyT5eJILSf42yRtWfaZrOOuvJXkie59m86kkb9rgWT+a5MtJ/jN7v0v+niQ/leSnFq9XkgcXf5a/S7KzpX+nW5O/DuiA/HvnrwM6IP/e+euADsi/d/46oAPy14HuHajF/wgAAAAANORDSgAAAACgMQMhAAAAADRmIAQAAACAxgyEAAAAANCYgRAAAAAAGjMQAgAAAEBjBkIAAAAAaOz/BwIeQ3PyHfM2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1296x1008 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_images=10\n",
    "fig, axs = plt.subplots(4, n_images, figsize=(18,14),tight_layout=True)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],axs=axs[0],max_clip_val=3500.)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],bands_show=[\"B11\",\"B8\", \"B4\"],\n",
    "                             axs=axs[1],max_clip_val=4500.)\n",
    "flooding_model.plot_batch_output_v1(batch_train[\"mask\"][:n_images, 0],axs=axs[2], show_axis=True)\n",
    "flooding_model.plot_batch_output_v1(prediction[:n_images] + 1,axs=axs[3], show_axis=True)\n",
    "\n",
    "for ax in axs.ravel():\n",
    "    ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model_params.max_tile_size = config.model_params.hyperparameters.max_tile_size\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from ml4floods.models.utils import metrics\n",
    "from ml4floods.models.model_setup import get_model_inference_function\n",
    "import pandas as pd\n",
    "\n",
    "# model.to(\"cuda\")\n",
    "inference_function = get_model_inference_function(model, config, apply_normalization=False, activation=\"softmax\")\n",
    "\n",
    "# config.data_params.batch_size = 8\n",
    "# dataset2 = get_dataset(config.data_params)\n",
    "dl = dataset.val_dataloader() # pytorch Dataloader\n",
    "print(str(dl.batch_size))\n",
    "\n",
    "# Otherwise fails when reading test dataset from remote bucket\n",
    "# torch.set_num_threads(1)\n",
    "\n",
    "thresholds_water = [0,1e-3,1e-2]+np.arange(0.5,.96,.05).tolist() + [.99,.995,.999]\n",
    "\n",
    "mets = metrics.compute_metrics(\n",
    "    dl,\n",
    "    inference_function, \n",
    "    thresholds_water=thresholds_water, \n",
    "    plot=False)\n",
    "\n",
    "label_names = [\"land\", \"water\", \"cloud\"]\n",
    "metrics.plot_metrics(mets, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(dl.dataset, \"image_files\"):\n",
    "    cems_code = [os.path.basename(f).split(\"_\")[0] for f in dl.dataset.image_files]\n",
    "else:\n",
    "    cems_code = [os.path.basename(f.file_name).split(\"_\")[0] for f in dl.dataset.list_of_windows]\n",
    "\n",
    "iou_per_code = pd.DataFrame(metrics.group_confusion(mets[\"confusions\"],cems_code, metrics.calculate_iou,\n",
    "                                                    label_names=[f\"IoU_{l}\"for l in [\"land\", \"water\", \"cloud\"]]))\n",
    "\n",
    "recall_per_code = pd.DataFrame(metrics.group_confusion(mets[\"confusions\"],cems_code, metrics.calculate_recall,\n",
    "                                                       label_names=[f\"Recall_{l}\"for l in [\"land\", \"water\", \"cloud\"]]))\n",
    "\n",
    "join_data_per_code = pd.merge(recall_per_code,iou_per_code,on=\"code\")\n",
    "join_data_per_code = join_data_per_code.set_index(\"code\")\n",
    "join_data_per_code = join_data_per_code*100\n",
    "print(f\"Mean values across flood events: {join_data_per_code.mean(axis=0).to_dict()}\")\n",
    "join_data_per_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_lightning.utilities.cloud_io import atomic_save\n",
    "from ml4floods.models.config_setup import save_json\n",
    "\n",
    "# Save in the cloud and in the wandb logger save dir\n",
    "atomic_save(model.state_dict(), f\"{experiment_path}/model.pt\")\n",
    "# Save cofig file in experiment_path\n",
    "config_file_path = f\"{experiment_path}/config.json\"\n",
    "save_json(config, config_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-consumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "if setup_weights_and_biases:\n",
    "    torch.save(model.state_dict(), os.path.join(wandb_logger.save_dir, 'model.pt'))\n",
    "    wandb.save(os.path.join(wandb_logger.save_dir, 'model.pt')) # Copy weights to weights and biases server\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-present",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt-gpu",
   "language": "python",
   "name": "pt-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
