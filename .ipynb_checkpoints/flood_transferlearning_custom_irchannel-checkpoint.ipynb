{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "early-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4,5,6,7\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-history",
   "metadata": {},
   "source": [
    "## Load flooding configuration file from local device or gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "toxic-watch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Config for experiment:  worldfloods_demo_test\n",
      "{   'data_params': {   'batch_size': 32,\n",
      "                       'bucket_id': 'ml4cc_data_lake',\n",
      "                       'channel_configuration': 'all',\n",
      "                       'download': {'test': True, 'train': True, 'val': True},\n",
      "                       'filter_windows': {   'apply': False,\n",
      "                                             'threshold_clouds': 0.5,\n",
      "                                             'version': 'v1'},\n",
      "                       'input_folder': 'S2',\n",
      "                       'loader_type': 'local',\n",
      "                       'num_workers': 4,\n",
      "                       'path_to_splits': 'worldfloods',\n",
      "                       'target_folder': 'gt',\n",
      "                       'test_transformation': {'normalize': True},\n",
      "                       'train_test_split_file': '2_PROD/2_Mart/worldfloods_v1_0/train_test_split.json',\n",
      "                       'train_transformation': {'normalize': True},\n",
      "                       'window_size': [256, 256]},\n",
      "    'deploy': False,\n",
      "    'experiment_name': 'worldfloods_demo_test',\n",
      "    'gpus': '0',\n",
      "    'model_params': {   'hyperparameters': {   'channel_configuration': 'all',\n",
      "                                               'early_stopping_patience': 4,\n",
      "                                               'label_names': [   'land',\n",
      "                                                                  'water',\n",
      "                                                                  'cloud'],\n",
      "                                               'lr': 0.0001,\n",
      "                                               'lr_decay': 0.5,\n",
      "                                               'lr_patience': 2,\n",
      "                                               'max_epochs': 10,\n",
      "                                               'max_tile_size': 256,\n",
      "                                               'metric_monitor': 'val_dice_loss',\n",
      "                                               'model_type': 'linear',\n",
      "                                               'num_channels': 13,\n",
      "                                               'num_classes': 3,\n",
      "                                               'val_every': 1,\n",
      "                                               'weight_per_class': [   1.93445299,\n",
      "                                                                       36.60054169,\n",
      "                                                                       2.19400729]},\n",
      "                        'model_folder': 'gs://ml4cc_data_lake/0_DEV/2_Mart/2_MLModelMart',\n",
      "                        'model_version': 'v1',\n",
      "                        'test': True,\n",
      "                        'train': True},\n",
      "    'resume_from_checkpoint': False,\n",
      "    'seed': 12,\n",
      "    'test': False,\n",
      "    'train': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'experiment_name': 'worldfloods_demo_test',\n",
       " 'seed': 12,\n",
       " 'model_params': {'model_folder': 'gs://ml4cc_data_lake/0_DEV/2_Mart/2_MLModelMart',\n",
       "  'model_version': 'v1',\n",
       "  'hyperparameters': {'max_tile_size': 256,\n",
       "   'metric_monitor': 'val_dice_loss',\n",
       "   'channel_configuration': 'all',\n",
       "   'label_names': ['land', 'water', 'cloud'],\n",
       "   'weight_per_class': [1.93445299, 36.60054169, 2.19400729],\n",
       "   'model_type': 'linear',\n",
       "   'num_classes': 3,\n",
       "   'max_epochs': 10,\n",
       "   'val_every': 1,\n",
       "   'lr': 0.0001,\n",
       "   'lr_decay': 0.5,\n",
       "   'lr_patience': 2,\n",
       "   'early_stopping_patience': 4,\n",
       "   'num_channels': 13},\n",
       "  'train': True,\n",
       "  'test': True},\n",
       " 'data_params': {'loader_type': 'local',\n",
       "  'num_workers': 4,\n",
       "  'filter_windows': {'version': 'v1', 'threshold_clouds': 0.5, 'apply': False},\n",
       "  'download': {'train': True, 'val': True, 'test': True},\n",
       "  'bucket_id': 'ml4cc_data_lake',\n",
       "  'path_to_splits': 'worldfloods',\n",
       "  'train_test_split_file': '2_PROD/2_Mart/worldfloods_v1_0/train_test_split.json',\n",
       "  'input_folder': 'S2',\n",
       "  'target_folder': 'gt',\n",
       "  'batch_size': 32,\n",
       "  'window_size': [256, 256],\n",
       "  'channel_configuration': 'all',\n",
       "  'train_transformation': {'normalize': True},\n",
       "  'test_transformation': {'normalize': True}},\n",
       " 'resume_from_checkpoint': False,\n",
       " 'train': False,\n",
       " 'gpus': '0',\n",
       " 'test': False,\n",
       " 'deploy': False}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ml4floods.models.config_setup import get_default_config\n",
    "import pkg_resources\n",
    "\n",
    "# Set filepath to configuration files\n",
    "# config_fp = 'path/to/worldfloods_template.json'\n",
    "config_fp = pkg_resources.resource_filename(\"ml4floods\",\"models/configurations/worldfloods_template.json\")\n",
    "\n",
    "config = get_default_config(config_fp)\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-scope",
   "metadata": {},
   "source": [
    "## Step 2: Setup Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defined-edgar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_folder': 'gs://ml4cc_data_lake/0_DEV/2_Mart/2_MLModelMart',\n",
       " 'model_version': 'v1',\n",
       " 'hyperparameters': {'max_tile_size': 256,\n",
       "  'metric_monitor': 'val_dice_loss',\n",
       "  'channel_configuration': 'bgriswir',\n",
       "  'label_names': ['land', 'water', 'cloud'],\n",
       "  'weight_per_class': [1.93445299, 36.60054169, 2.19400729],\n",
       "  'model_type': 'linear',\n",
       "  'num_classes': 3,\n",
       "  'max_epochs': 10,\n",
       "  'val_every': 1,\n",
       "  'lr': 0.0001,\n",
       "  'lr_decay': 0.5,\n",
       "  'lr_patience': 2,\n",
       "  'early_stopping_patience': 4,\n",
       "  'num_channels': 5},\n",
       " 'train': True,\n",
       " 'test': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.experiment_name = 'training_flooding_bgriswir'\n",
    "config.data_params.channel_configuration = 'bgriswir'\n",
    "config.model_params.hyperparameters.channel_configuration = 'bgriswir'\n",
    "config.model_params.hyperparameters.num_channels = 5\n",
    "config.data_params.bucket_id = \"\"\n",
    "config.model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "scientific-musician",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 194151  tiles\n",
      "val 1284  tiles\n",
      "test 11  tiles\n",
      "CPU times: user 3.94 s, sys: 2.2 s, total: 6.14 s\n",
      "Wall time: 6.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from ml4floods.models.dataset_setup import get_dataset\n",
    "\n",
    "config.data_params.batch_size = 16 # control this depending on the space on your GPU!\n",
    "config.data_params.loader_type = 'local'\n",
    "config.data_params.path_to_splits = \"/mnt/d/Flooding/worldfloods_v1_0\" # local folder to download the data\n",
    "config.data_params.train_test_split_file = \"/mnt/d/Flooding/train_test_split_local.json\"\n",
    "\n",
    "config.data_params[\"download\"] = {\"train\": True, \"val\": True, \"test\": True} # download only test data\n",
    "# config.data_params.train_test_split_file = \"2_PROD/2_Mart/worldfloods_v1_0/train_test_split.json\" # use this to train with all the data\n",
    "config.data_params.num_workers = 4\n",
    "\n",
    "# If files are not in config.data_params.path_to_splits this will trigger the download of the products.\n",
    "dataset = get_dataset(config.data_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-harassment",
   "metadata": {},
   "source": [
    "## Verfify data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-driver",
   "metadata": {},
   "source": [
    "#### Verify training data\n",
    "Data format here: https://github.com/spaceml-org/ml4floods/blob/891fe602880586e7ac821d2f282bf5ec9d4c0795/ml4floods/data/worldfloods/dataset.py#L106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fallen-harbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12135\n"
     ]
    }
   ],
   "source": [
    "train_dl = dataset.train_dataloader()\n",
    "train_dl_iter = iter(train_dl)\n",
    "print(len(train_dl_iter))\n",
    "batch_train = next(train_dl_iter)\n",
    "\n",
    "# batch_train[\"image\"].shape, batch_train[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-spanking",
   "metadata": {},
   "source": [
    "Verify validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "injured-effect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "val_dl = dataset.val_dataloader()\n",
    "\n",
    "val_dl_iter = iter(val_dl)\n",
    "print(len(val_dl_iter))\n",
    "batch_val = next(val_dl_iter)\n",
    "\n",
    "# batch_val[\"image\"].shape, batch_val[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "significant-multiple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "test_dl = dataset.test_dataloader()\n",
    "\n",
    "test_dl_iter = iter(test_dl)\n",
    "print(len(test_dl_iter))\n",
    "\n",
    "batch_test = next(test_dl_iter)\n",
    "# batch_test[\"image\"].shape, batch_test[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-electron",
   "metadata": {},
   "source": [
    "### Plot batch by using ml4flood model \n",
    "check detail here: https://github.com/spaceml-org/ml4floods/blob/891fe602880586e7ac821d2f282bf5ec9d4c0795/ml4floods/data/worldfloods/dataset.py#L106"
   ]
  },
  {
   "cell_type": "raw",
   "id": "31b26d6b-ecc5-4648-92f5-299b6099f321",
   "metadata": {},
   "source": [
    "from models import flooding_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "flooding_model.plot_batch(batch_train[\"image\"])\n",
    "\n",
    "n_images=6\n",
    "fig, axs = plt.subplots(3,n_images, figsize=(18,10),tight_layout=True)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],axs=axs[0],max_clip_val=3500.)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],bands_show=[\"B11\",\"B8\", \"B4\"],\n",
    "                             axs=axs[1],max_clip_val=4500.)\n",
    "flooding_model.plot_batch_output_v1(batch_train[\"mask\"][:n_images, 0],axs=axs[2], show_axis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7279717-cfb1-4d20-a915-869d1ab3ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "from models import flooding_model\n",
    "flooding_model = importlib.reload(flooding_model)\n",
    "\n",
    "# batch_train_rgb = flooding_model.batch_to_unnorm_rgb(batch_train[\"image\"])\n",
    "# # batch_train_rgb.shape\n",
    "# plt.imshow(batch_train_rgb[2])\n",
    "# plt.show()\n",
    "\n",
    "# batch_train_rgb_mask = flooding_model.batch_mask_to_rgb(batch_train[\"mask\"])\n",
    "# plt.imshow(batch_train_rgb_mask[2])\n",
    "# plt.colorbar()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-cleanup",
   "metadata": {},
   "source": [
    "## Step 3: Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "proud-surrey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_folder': 'gs://ml4cc_data_lake/0_DEV/2_Mart/2_MLModelMart',\n",
       " 'model_version': 'v1',\n",
       " 'hyperparameters': {'max_tile_size': 256,\n",
       "  'metric_monitor': 'val_dice_loss',\n",
       "  'channel_configuration': 'bgriswir',\n",
       "  'label_names': ['land', 'water', 'cloud'],\n",
       "  'weight_per_class': [1.93445299, 36.60054169, 2.19400729],\n",
       "  'model_type': 'linear',\n",
       "  'num_classes': 3,\n",
       "  'max_epochs': 10,\n",
       "  'val_every': 1,\n",
       "  'lr': 0.0001,\n",
       "  'lr_decay': 0.5,\n",
       "  'lr_patience': 2,\n",
       "  'early_stopping_patience': 4,\n",
       "  'num_channels': 5},\n",
       " 'train': True,\n",
       " 'test': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # folder to store the trained model (it will create a subfolder with the name of the experiment)\n",
    "config.model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "colonial-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model_params.model_folder = \"train_models\" \n",
    "os.makedirs(\"train_models\", exist_ok=True)\n",
    "config.model_params.test = False\n",
    "config.model_params.train = True\n",
    "config.model_params.hyperparameters.model_type = \"unet\" # Currently implemented: simplecnn, unet, linear\n",
    "config.model_params.hyperparameters.metric_monitor = 'val_iou_loss' #IoU Loss\n",
    "# config.model_params.hyperparameters.num_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alternative-bonus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of channels:  5 , num of classes:  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (dconv_down1): Sequential(\n",
       "    (0): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_down2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_down3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_down4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dconv_up3): Sequential(\n",
       "    (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_up2): Sequential(\n",
       "    (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_up1): Sequential(\n",
       "    (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_last): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "from models.flooding_model import WorldFloodsModel, DistilledTrainingModel, WorldFloodsModel2, WorldFloodsModel1\n",
    "importlib.reload(flooding_model)\n",
    "simple_model_params = copy.deepcopy(config.model_params)\n",
    "simple_model_params['hyperparameters']['model_type']=\"unet_simple\"\n",
    "\n",
    "# model = DistilledTrainingModel(config.model_params, simple_model_params)\n",
    "model = WorldFloodsModel2(config.model_params) # Focal loss and IoU loss\n",
    "# model = WorldFloodsModel1(config.model_params) # Focal loss and Dice loss\n",
    "net = model.network\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c4307a4-d88a-417c-94aa-4dd145299a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module UNet is treated as a zero-op.\n",
      "UNet(\n",
      "  7.784 M, 100.000% Params, 42.548 GMac, 100.000% MACs, \n",
      "  (dconv_down1): Sequential(\n",
      "    0.04 M, 0.512% Params, 2.621 GMac, 6.161% MACs, \n",
      "    (0): Conv2d(0.003 M, 0.038% Params, 0.193 GMac, 0.453% MACs, 5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.010% MACs, inplace=True)\n",
      "    (2): Conv2d(0.037 M, 0.474% Params, 2.42 GMac, 5.688% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.010% MACs, inplace=True)\n",
      "  )\n",
      "  (dconv_down2): Sequential(\n",
      "    0.221 M, 2.845% Params, 3.632 GMac, 8.537% MACs, \n",
      "    (0): Conv2d(0.074 M, 0.949% Params, 1.21 GMac, 2.844% MACs, 64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.005% MACs, inplace=True)\n",
      "    (2): Conv2d(0.148 M, 1.896% Params, 2.418 GMac, 5.683% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.005% MACs, inplace=True)\n",
      "  )\n",
      "  (dconv_down3): Sequential(\n",
      "    0.885 M, 11.372% Params, 3.628 GMac, 8.527% MACs, \n",
      "    (0): Conv2d(0.295 M, 3.792% Params, 1.209 GMac, 2.841% MACs, 128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "    (2): Conv2d(0.59 M, 7.580% Params, 2.417 GMac, 5.681% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "  )\n",
      "  (dconv_down4): Sequential(\n",
      "    3.54 M, 45.476% Params, 3.626 GMac, 8.522% MACs, \n",
      "    (0): Conv2d(1.18 M, 15.161% Params, 1.208 GMac, 2.840% MACs, 256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "    (2): Conv2d(2.36 M, 30.315% Params, 2.416 GMac, 5.679% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "  )\n",
      "  (maxpool): MaxPool2d(0.0 M, 0.000% Params, 0.007 GMac, 0.017% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dconv_up3): Sequential(\n",
      "    2.36 M, 30.315% Params, 9.668 GMac, 22.722% MACs, \n",
      "    (0): Conv2d(1.77 M, 22.735% Params, 7.249 GMac, 17.037% MACs, 768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "    (2): Conv2d(0.59 M, 7.580% Params, 2.417 GMac, 5.681% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "  )\n",
      "  (dconv_up2): Sequential(\n",
      "    0.59 M, 7.580% Params, 9.672 GMac, 22.732% MACs, \n",
      "    (0): Conv2d(0.442 M, 5.685% Params, 7.25 GMac, 17.039% MACs, 384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.005% MACs, inplace=True)\n",
      "    (2): Conv2d(0.148 M, 1.896% Params, 2.418 GMac, 5.683% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.005% MACs, inplace=True)\n",
      "  )\n",
      "  (dconv_up1): Sequential(\n",
      "    0.148 M, 1.896% Params, 9.68 GMac, 22.752% MACs, \n",
      "    (0): Conv2d(0.111 M, 1.422% Params, 7.252 GMac, 17.044% MACs, 192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.010% MACs, inplace=True)\n",
      "    (2): Conv2d(0.037 M, 0.474% Params, 2.42 GMac, 5.688% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.010% MACs, inplace=True)\n",
      "  )\n",
      "  (conv_last): Conv2d(0.0 M, 0.003% Params, 0.013 GMac, 0.030% MACs, 64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Computational complexity:       42.55 GMac\n",
      "Number of parameters:           7.78 M  \n"
     ]
    }
   ],
   "source": [
    "# Compuatation complexity of network\n",
    "from ptflops import get_model_complexity_info\n",
    "macs, params = get_model_complexity_info(net, (config.model_params.hyperparameters.num_channels, config.model_params.hyperparameters.max_tile_size, config.model_params.hyperparameters.max_tile_size), as_strings=True, print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "seventh-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_weights_and_biases = False\n",
    "if setup_weights_and_biases:\n",
    "    import wandb\n",
    "    from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "    # UNCOMMENT ON FIRST RUN TO LOGIN TO Weights and Biases (only needs to be done once)\n",
    "    # wandb.login()\n",
    "    # run = wandb.init()\n",
    "\n",
    "    # Specifies who is logging the experiment to wandb\n",
    "    config['wandb_entity'] = 'ml4floods'\n",
    "    # Specifies which wandb project to log to, multiple runs can exist in the same project\n",
    "    config['wandb_project'] = 'worldfloods-notebook-demo-project'\n",
    "\n",
    "    wandb_logger = WandbLogger(\n",
    "        name=config.experiment_name,\n",
    "        project=config.wandb_project, \n",
    "        entity=config.wandb_entity\n",
    "    )\n",
    "else:\n",
    "    wandb_logger = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "downtown-teens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trained model will be stored in train_models/training_flooding_bgriswir\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "experiment_path = f\"{config.model_params.model_folder}/{config.experiment_name}\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"{experiment_path}/checkpoint\",\n",
    "    save_top_k=True,\n",
    "    verbose=True,\n",
    "    monitor='val_iou_loss',\n",
    "    mode='min',\n",
    "#     prefix=''\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_iou_loss',\n",
    "    patience=10,\n",
    "    strict=False,\n",
    "    verbose=False,\n",
    "    mode='min'\n",
    ")\n",
    "# monitor='val_iou_loss'\n",
    "# monitor='val_dice_loss'\n",
    "\n",
    "\n",
    "callbacks = [checkpoint_callback, early_stop_callback]\n",
    "\n",
    "print(f\"The trained model will be stored in {config.model_params.model_folder}/{config.experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "searching-charity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeaiserver/pt-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/eeaiserver/pt-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:33: LightningDeprecationWarning: Setting `log_gpu_memory` with the trainer flag is deprecated in v1.5 and will be removed in v1.7. Please monitor GPU stats with the `DeviceStatsMonitor` callback directly instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/eeaiserver/pt-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:45: LightningDeprecationWarning: Setting `Trainer(resume_from_checkpoint=)` is deprecated in v1.5 and will be removed in v1.7. Please pass `Trainer.fit(ckpt_path=)` directly instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "config.gpus = 4 # which gpu to use\n",
    "# config.gpus = None # to not use GPU\n",
    "config.model_params.hyperparameters.max_epochs = 40 # train for maximum 4 epochs\n",
    "\n",
    "trainer = Trainer(\n",
    "    fast_dev_run=False,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=callbacks,\n",
    "    default_root_dir=f\"{config.model_params.model_folder}/{config.experiment_name}\",\n",
    "    accumulate_grad_batches=1,\n",
    "    gradient_clip_val=0.0,\n",
    "    auto_lr_find=False,\n",
    "    benchmark=False,\n",
    "    gpus=config.gpus,\n",
    "    max_epochs=config.model_params.hyperparameters.max_epochs,\n",
    "    check_val_every_n_epoch=config.model_params.hyperparameters.val_every,\n",
    "    log_gpu_memory=False,\n",
    "    accelerator='dp',\n",
    "    resume_from_checkpoint='/home/eeaiserver/viplab_projects/satellite-knowledge-distillation/train_models/training_flooding_bgriswir/checkpoint/epoch=8-step=109214.ckpt'\n",
    ")\n",
    "# config\n",
    "# https://wandb.ai/wandb/wandb-lightning/reports/Multi-GPU-Training-Using-PyTorch-Lightning--VmlldzozMTk3NTk\n",
    "# resume_from_checkpoint='/home/eeaiserver/viplab_projects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=39-step=161799.ckpt'\n",
    "# resume_from_checkpoint='~/Projects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=30-step=47026.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-india",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeaiserver/pt-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1907: LightningDeprecationWarning: `trainer.resume_from_checkpoint` is deprecated in v1.5 and will be removed in v1.7. Specify the fit checkpoint path with `trainer.fit(ckpt_path=)` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/eeaiserver/pt-gpu/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "Restoring states from the checkpoint path at /home/eeaiserver/viplab_projects/satellite-knowledge-distillation/train_models/training_flooding_bgriswir/checkpoint/epoch=8-step=109214.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [4,5,6,7]\n",
      "/home/eeaiserver/pt-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:247: UserWarning: You're resuming from a checkpoint that ended mid-epoch. Training will start from the beginning of the next epoch. This can cause unreliable results if further training is done, consider using an end of epoch checkpoint.\n",
      "  rank_zero_warn(\n",
      "Restored all states from the checkpoint file at /home/eeaiserver/viplab_projects/satellite-knowledge-distillation/train_models/training_flooding_bgriswir/checkpoint/epoch=8-step=109214.ckpt\n",
      "\n",
      "  | Name    | Type | Params\n",
      "---------------------------------\n",
      "0 | network | UNet | 7.8 M \n",
      "---------------------------------\n",
      "7.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.8 M     Total params\n",
      "31.137    Total estimated model params size (MB)\n",
      "/home/eeaiserver/pt-gpu/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/eeaiserver/viplab_projects/satellite-knowledge-distillation/train_models/training_flooding_bgriswir/checkpoint exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeaiserver/pt-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:116: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a127f6f0babb4091a65263aa9cc8cf62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 121349: val_iou_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 133484: val_iou_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 145619: val_iou_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 157754: val_iou_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 169889: val_iou_loss reached 0.24502 (best 0.24502), saving model to \"/home/eeaiserver/viplab_projects/satellite-knowledge-distillation/train_models/training_flooding_bgriswir/checkpoint/epoch=13-step=169889.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 182024: val_iou_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 194159: val_iou_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 206294: val_iou_loss reached 0.24419 (best 0.24419), saving model to \"/home/eeaiserver/viplab_projects/satellite-knowledge-distillation/train_models/training_flooding_bgriswir/checkpoint/epoch=16-step=206294.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 218429: val_iou_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 230564: val_iou_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 242699: val_iou_loss was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    19: reducing learning rate of group 0 to 2.5000e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 254834: val_iou_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 266969: val_iou_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 279104: val_iou_loss was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    22: reducing learning rate of group 0 to 1.2500e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 291239: val_iou_loss reached 0.24377 (best 0.24377), saving model to \"/home/eeaiserver/viplab_projects/satellite-knowledge-distillation/train_models/training_flooding_bgriswir/checkpoint/epoch=23-step=291239.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 303374: val_iou_loss reached 0.24335 (best 0.24335), saving model to \"/home/eeaiserver/viplab_projects/satellite-knowledge-distillation/train_models/training_flooding_bgriswir/checkpoint/epoch=24-step=303374.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 315509: val_iou_loss reached 0.24213 (best 0.24213), saving model to \"/home/eeaiserver/viplab_projects/satellite-knowledge-distillation/train_models/training_flooding_bgriswir/checkpoint/epoch=25-step=315509.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 327644: val_iou_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, global step 339779: val_iou_loss reached 0.23733 (best 0.23733), saving model to \"/home/eeaiserver/viplab_projects/satellite-knowledge-distillation/train_models/training_flooding_bgriswir/checkpoint/epoch=27-step=339779.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, global step 351914: val_iou_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 364049: val_iou_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30, global step 376184: val_iou_loss reached 0.23543 (best 0.23543), saving model to \"/home/eeaiserver/viplab_projects/satellite-knowledge-distillation/train_models/training_flooding_bgriswir/checkpoint/epoch=30-step=376184.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31, global step 388319: val_iou_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32, global step 400454: val_iou_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33, global step 412589: val_iou_loss was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    33: reducing learning rate of group 0 to 6.2500e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34, global step 424724: val_iou_loss was not in top True\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# Run inference on the images shown before\n",
    "\n",
    "logits = model(batch_train[\"image\"].to(model.device))\n",
    "print(f\"Shape of logits: {logits.shape}\")\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "print(f\"Shape of probs: {probs.shape}\")\n",
    "prediction = torch.argmax(probs, dim=1).long().cpu()\n",
    "print(f\"Shape of prediction: {prediction.shape}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3eb6095c-4b3f-47db-8920-92242e50f36b",
   "metadata": {},
   "source": [
    "n_images=10\n",
    "fig, axs = plt.subplots(4, n_images, figsize=(18,14),tight_layout=True)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],axs=axs[0],max_clip_val=3500.)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],bands_show=[\"B11\",\"B8\", \"B4\"],\n",
    "                             axs=axs[1],max_clip_val=4500.)\n",
    "flooding_model.plot_batch_output_v1(batch_train[\"mask\"][:n_images, 0],axs=axs[2], show_axis=True)\n",
    "flooding_model.plot_batch_output_v1(prediction[:n_images] + 1,axs=axs[3], show_axis=True)\n",
    "\n",
    "for ax in axs.ravel():\n",
    "    ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model_params.max_tile_size = config.model_params.hyperparameters.max_tile_size\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "# import torch\n",
    "import numpy as np\n",
    "from ml4floods.models.utils import metrics\n",
    "from ml4floods.models.model_setup import get_model_inference_function\n",
    "import pandas as pd\n",
    "\n",
    "# model.to(\"cuda\")\n",
    "inference_function = get_model_inference_function(model, config, apply_normalization=False, activation=\"softmax\")\n",
    "\n",
    "# dataset2 = get_dataset(config.data_params)\n",
    "dl = dataset.val_dataloader() # pytorch Dataloader\n",
    "print(str(dl.batch_size))\n",
    "\n",
    "# Otherwise fails when reading test dataset from remote bucket\n",
    "# torch.set_num_threads(1)\n",
    "\n",
    "thresholds_water = [0,1e-3,1e-2]+np.arange(0.5,.96,.05).tolist() + [.99,.995,.999]\n",
    "\n",
    "mets = metrics.compute_metrics(\n",
    "    dl,\n",
    "    inference_function, \n",
    "    thresholds_water=thresholds_water, \n",
    "    plot=False, convert_targets=False)\n",
    "\n",
    "label_names = [\"land\", \"water\", \"cloud\"]\n",
    "metrics.plot_metrics(mets, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(dl.dataset, \"image_files\"):\n",
    "    cems_code = [os.path.basename(f).split(\"_\")[0] for f in dl.dataset.image_files]\n",
    "else:\n",
    "    cems_code = [os.path.basename(f.file_name).split(\"_\")[0] for f in dl.dataset.list_of_windows]\n",
    "\n",
    "iou_per_code = pd.DataFrame(metrics.group_confusion(mets[\"confusions\"],cems_code, metrics.calculate_iou,\n",
    "                                                    label_names=[f\"IoU_{l}\"for l in [\"land\", \"water\", \"cloud\"]]))\n",
    "\n",
    "recall_per_code = pd.DataFrame(metrics.group_confusion(mets[\"confusions\"],cems_code, metrics.calculate_recall,\n",
    "                                                       label_names=[f\"Recall_{l}\"for l in [\"land\", \"water\", \"cloud\"]]))\n",
    "\n",
    "join_data_per_code = pd.merge(recall_per_code,iou_per_code,on=\"code\")\n",
    "join_data_per_code = join_data_per_code.set_index(\"code\")\n",
    "join_data_per_code = join_data_per_code*100\n",
    "print(f\"Mean values across flood events: {join_data_per_code.mean(axis=0).to_dict()}\")\n",
    "join_data_per_code"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6233dfa4-7736-4f55-a3a1-ca90f6bd8944",
   "metadata": {},
   "source": [
    "# import torch\n",
    "from pytorch_lightning.utilities.cloud_io import atomic_save\n",
    "from ml4floods.models.config_setup import save_json\n",
    "\n",
    "# Save in the cloud and in the wandb logger save dir\n",
    "atomic_save(model.state_dict(), f\"{experiment_path}/model_rgbnir_worldflood_model_2_epoch_10.pt\")\n",
    "# Save cofig file in experiment_path\n",
    "config_file_path = f\"{experiment_path}/config_rgbnir_worldflood_model_2_epoch_10.json\"\n",
    "save_json(config, config_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1b6829-07cf-4831-b114-20230d3b3289",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),f\"{experiment_path}/model_bgriswir_worldflood_model_1_epoch_2_gamma_5_alpha_0_001.pt\")\n",
    "# Save cofig file in experiment_path\n",
    "config_file_path = f\"{experiment_path}/config_bgriswir_worldflood_model_1_epoch_2_gamma_5_alpha_0_001.json\"\n",
    "import json\n",
    "with open(config_file_path, 'w') as f:\n",
    "    json.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-consumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "if setup_weights_and_biases:\n",
    "    torch.save(model.state_dict(), os.path.join(wandb_logger.save_dir, 'model_bgriswir_worldflood_model_1_epoch_2_gamma_5_alpha_0_001.pt'))\n",
    "    wandb.save(os.path.join(wandb_logger.save_dir, 'model_bgriswir_worldflood_model_1_epoch_2_gamma_5_alpha_0_001.pt')) # Copy weights to weights and biases server\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28f5845-b502-41df-afdb-df2af60b5696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on the images shown before\n",
    "\n",
    "logits = model(batch_val[\"image\"].to(model.device))\n",
    "print(f\"Shape of logits: {logits.shape}\")\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "print(f\"Shape of probs: {probs.shape}\")\n",
    "prediction = torch.argmax(probs, dim=1).long().cpu()\n",
    "print(f\"Shape of prediction: {prediction.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbafaab-0986-4de8-98ef-0bfb21c439d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_image_start=7\n",
    "n_images=14\n",
    "count=int(n_images-n_image_start)\n",
    "fig, axs = plt.subplots(4, count, figsize=(18,14),tight_layout=True)\n",
    "importlib.reload(flooding_model)\n",
    "flooding_model.plot_batch(batch_val[\"image\"][n_image_start:n_images],channel_configuration=\"bgri\",axs=axs[0],max_clip_val=3500.)\n",
    "flooding_model.plot_batch(batch_val[\"image\"][n_image_start:n_images],channel_configuration=\"bgri\",bands_show=[\"B8\",\"B8\", \"B8\"],axs=axs[1],max_clip_val=3500.)\n",
    "# flooding_model.plot_batch(batch_val[\"image\"][:n_images],bands_show=[\"B11\",\"B8\", \"B4\"],axs=axs[1],max_clip_val=4500.)\n",
    "flooding_model.plot_batch_output_v1(batch_val[\"mask\"][n_image_start:n_images, 0],axs=axs[2], show_axis=True)\n",
    "flooding_model.plot_batch_output_v1(prediction[n_image_start:n_images] + 1,axs=axs[3], show_axis=True)\n",
    "\n",
    "for ax in axs.ravel():\n",
    "    ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f0f77-f767-42bd-95d3-7436e91cf27e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt-gpu",
   "language": "python",
   "name": "pt-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
