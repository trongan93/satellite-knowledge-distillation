{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "loved-granny",
   "metadata": {},
   "source": [
    "Knowledge distillation on for UNET\n",
    "Ref: https://github.com/VaticanCameos99/knowledge-distillation-for-unet/blob/master/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "shared-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "# import dataset\n",
    "import numpy as np\n",
    "from models.unet_optimize import UNet, SimpleUNet\n",
    "from models.losses import loss_fn_kd\n",
    "from models.metrics import dice_loss\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "021c006e-02ef-4896-a72c-c9a62a54488f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Config for experiment:  training_flooding\n",
      "{   'data_params': {   'batch_size': 32,\n",
      "                       'bucket_id': 'ml4cc_data_lake',\n",
      "                       'channel_configuration': 'all',\n",
      "                       'download': {'test': True, 'train': True, 'val': True},\n",
      "                       'filter_windows': {   'apply': False,\n",
      "                                             'threshold_clouds': 0.5,\n",
      "                                             'version': 'v1'},\n",
      "                       'input_folder': 'S2',\n",
      "                       'loader_type': 'local',\n",
      "                       'num_workers': 4,\n",
      "                       'path_to_splits': '/mnt/d/Flooding/worldfloods_v1_sample',\n",
      "                       'target_folder': 'gt',\n",
      "                       'test_transformation': {'normalize': True},\n",
      "                       'train_test_split_file': '2_PROD/2_Mart/worldfloods_v1_0/train_test_split.json',\n",
      "                       'train_transformation': {'normalize': True},\n",
      "                       'window_size': [256, 256]},\n",
      "    'deploy': False,\n",
      "    'experiment_name': 'training_flooding',\n",
      "    'gpus': '0',\n",
      "    'model_params': {   'hyperparameters': {   'channel_configuration': 'all',\n",
      "                                               'early_stopping_patience': 4,\n",
      "                                               'label_names': [   'land',\n",
      "                                                                  'water',\n",
      "                                                                  'cloud'],\n",
      "                                               'lr': 0.0001,\n",
      "                                               'lr_decay': 0.5,\n",
      "                                               'lr_patience': 2,\n",
      "                                               'max_epochs': 10,\n",
      "                                               'max_tile_size': 256,\n",
      "                                               'metric_monitor': 'val_dice_loss',\n",
      "                                               'model_type': 'unet',\n",
      "                                               'num_channels': 13,\n",
      "                                               'num_classes': 3,\n",
      "                                               'val_every': 1,\n",
      "                                               'weight_per_class': [   1.93445299,\n",
      "                                                                       36.60054169,\n",
      "                                                                       2.19400729]},\n",
      "                        'max_tile_size': 256,\n",
      "                        'model_folder': 'train_models',\n",
      "                        'model_version': 'v1',\n",
      "                        'test': False,\n",
      "                        'train': True},\n",
      "    'resume_from_checkpoint': False,\n",
      "    'seed': 12,\n",
      "    'test': False,\n",
      "    'train': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'train_models/training_flooding/model.pt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ml4floods.models.config_setup import get_default_config\n",
    "config_fp = \"train_models/training_flooding/config.json\"\n",
    "config = get_default_config(config_fp)\n",
    "config.data_params.data_params='ml4cc_data_lake'\n",
    "path_to_models = os.path.join(config.model_params.model_folder,config.experiment_name, \"model.pt\").replace(\"\\\\\",\"/\")\n",
    "teacher_weights = path_to_models\n",
    "teacher_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0af2a8b7-e362-4354-be5e-ac9b200e5413",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = config.model_params.hyperparameters.num_channels\n",
    "num_classes = config.model_params.hyperparameters.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18a2db80-c218-4c02-aeab-921dbb52ab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_teacher_outputs(teacher, train_loader):\n",
    "    print('-------Fetch teacher outputs-------')\n",
    "    teacher.eval().cuda()\n",
    "    #list of tensors\n",
    "    teacher_outputs = []\n",
    "    with torch.no_grad():\n",
    "        #trainloader gets bs images at a time. why does enumerate(tl) run for all images?\n",
    "        for i, (img, gt) in enumerate(train_loader):\n",
    "            print(i, 'i')\n",
    "            '''img = img[0, :, :, :, :]\n",
    "            gt = gt[0, :, :, :, :]'''\n",
    "            if torch.cuda.is_available():\n",
    "                img = img.cuda()\n",
    "            img = Variable(img)\n",
    "\n",
    "            output = teacher(img)\n",
    "            teacher_outputs.append(output)\n",
    "    return teacher_outputs\n",
    "\n",
    "def train_student(student, teacher_outputs, optimizer, train_loader):\n",
    "    print('-------Train student-------')\n",
    "    #called once for each epoch\n",
    "    student.train().cuda()\n",
    "\n",
    "    summ = []\n",
    "    for i, (img, gt) in enumerate(train_loader):\n",
    "        teacher_output = teacher_outputs[i]\n",
    "        if torch.cuda.is_available():\n",
    "            img, gt = img.cuda(), gt.cuda()\n",
    "            teacher_output = teacher_output.cuda()\n",
    "\n",
    "        img, gt = Variable(img), Variable(gt)\n",
    "        teacher_output =  Variable(teacher_output)\n",
    "\n",
    "        output = student(img)\n",
    "\n",
    "        #TODO: loss is wrong\n",
    "        loss = loss_fn_kd(output, teacher_output, gt)    \n",
    "\n",
    "        # clear previous gradients, compute gradients of all variables wrt loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # performs updates using calculated gradients\n",
    "        optimizer.step()\n",
    "        if i % summary_steps == 0:\n",
    "            #do i need to move it to CPU?\n",
    "            \n",
    "            metric = dice_loss(output, gt)\n",
    "            summary = {'metric' : metric.item(), 'loss' : loss.item()}\n",
    "            summ.append(summary)\n",
    "    \n",
    "    #print('Average loss over this epoch: ' + np.mean(loss_avg))\n",
    "    mean_dice_coeff =  np.mean([x['metric'] for x in summ])\n",
    "    mean_loss = np.mean([x['loss'] for x in summ])\n",
    "    print('- Train metrics:\\n' + '\\tMetric:{}\\n\\tLoss:{}'.format(mean_dice_coeff, mean_loss))\n",
    "    #print accuracy and loss\n",
    "\n",
    "def evaluate_kd(student, val_loader):\n",
    "    print('-------Evaluate student-------')\n",
    "    student.eval().cuda()\n",
    "\n",
    "    #criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    loss_summ = []\n",
    "    with torch.no_grad():\n",
    "        for i, (img, gt) in enumerate(val_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                img, gt = img.cuda(), gt.cuda()\n",
    "            img, gt = Variable(img), Variable(gt)\n",
    "\n",
    "            output = student(img)\n",
    "            output = output.clamp(min = 0, max = 1)\n",
    "            loss = dice_loss(output, gt)\n",
    "\n",
    "            loss_summ.append(loss.item())\n",
    "\n",
    "    mean_loss = np.mean(loss_summ)\n",
    "    print('- Eval metrics:\\n\\tAverage Dice loss:{}'.format(mean_loss))\n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b767bf9c-078d-4b77-9a45-1ca1cb86f4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# teacher = UNet(num_channels, num_classes)\n",
    "# student = SimpleUNet(num_channels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba2192c5-fe5d-4446-a177-90f9e0edf3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(student.parameters(), lr=1e-3)\n",
    "scheduler = StepLR(optimizer, step_size = 100, gamma = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a19c8539-3bb0-4a2a-b3a1-5be321cfc9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_models/training_flooding/model.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.flooding_model import WorldFloodsModel\n",
    "teacher_model = WorldFloodsModel(config.model_params)\n",
    "path_to_models = os.path.join(config.model_params.model_folder,config.experiment_name, \"model.pt\").replace(\"\\\\\",\"/\")\n",
    "print(path_to_models)\n",
    "from pytorch_lightning.utilities.cloud_io import load\n",
    "teacher_model.load_state_dict(load(path_to_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eac871-c571-4fd5-9509-dd0f5b0bf08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt-gpu",
   "language": "python",
   "name": "pt-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
